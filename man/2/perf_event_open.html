<!DOCTYPE html>
<html lang=en-US>
<head>
<meta charset=utf-8>
<title>Linux command perf_event_open</title><meta name="description" content="Linux command perf_event_open set up performance monitoring"><meta name="keywords" content="linux, command, perf_event_open, bsd, set up performance monitoring"><meta name="robots" content="index,follow">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
<div class="container">

<h1>NAME</h1>
<p>perf_event_open - set up performance monitoring</p>
<h1>SYNOPSIS</h1>
<pre><code>#include &lt;linux/perf_event.h&gt;
#include &lt;linux/hw_breakpoint.h&gt;

int perf_event_open(struct perf_event_attr *attr,
 pid_t pid, int cpu, int group_fd,
 unsigned long flags);</code></pre>
<p><em>Note</em>: There is no glibc wrapper for this system call; see NOTES.</p>
<h1>DESCRIPTION</h1>
<p>Given a list of parameters, <strong>perf_event_open</strong>() returns a file descriptor, for use in subsequent system calls (<strong>read</strong>(2), <strong>mmap</strong>(2), <strong>prctl</strong>(2), <strong>fcntl</strong>(2), etc.).</p>
<p>A call to <strong>perf_event_open</strong>() creates a file descriptor that allows measuring performance information. Each file descriptor corresponds to one event that is measured; these can be grouped together to measure multiple events simultaneously.</p>
<p>Events can be enabled and disabled in two ways: via <strong>ioctl</strong>(2) and via <strong>prctl</strong>(2). When an event is disabled it does not count or generate overflows but does continue to exist and maintain its count value.</p>
<p>Events come in two flavors: counting and sampled. A <em>counting</em> event is one that is used for counting the aggregate number of events that occur. In general, counting event results are gathered with a <strong>read</strong>(2) call. A <em>sampling</em> event periodically writes measurements to a buffer that can then be accessed via <strong>mmap</strong>(2).</p>
<h2>Arguments</h2>
<p>The <em>pid</em> and <em>cpu</em> arguments allow specifying which process and CPU to monitor:</p>
<dl>
<dt><strong>pid == 0</strong> and <strong>cpu == -1</strong></dt>
<dd><p>This measures the calling process/thread on any CPU.</p>
</dd>
<dt><strong>pid == 0</strong> and <strong>cpu &gt;= 0</strong></dt>
<dd><p>This measures the calling process/thread only when running on the specified CPU.</p>
</dd>
<dt><strong>pid &gt; 0</strong> and <strong>cpu == -1</strong></dt>
<dd><p>This measures the specified process/thread on any CPU.</p>
</dd>
<dt><strong>pid &gt; 0</strong> and <strong>cpu &gt;= 0</strong></dt>
<dd><p>This measures the specified process/thread only when running on the specified CPU.</p>
</dd>
<dt><strong>pid == -1</strong> and <strong>cpu &gt;= 0</strong></dt>
<dd><p>This measures all processes/threads on the specified CPU. This requires <strong>CAP_PERFMON</strong> (since Linux 5.8) or <strong>CAP_SYS_ADMIN</strong> capability or a <em>/proc/sys/kernel/perf_event_paranoid</em> value of less than 1.</p>
</dd>
<dt><strong>pid == -1</strong> and <strong>cpu == -1</strong></dt>
<dd><p>This setting is invalid and will return an error.</p>
</dd>
</dl>
<p>When <em>pid</em> is greater than zero, permission to perform this system call is governed by <strong>CAP_PERFMON</strong> (since Linux 5.9) and a ptrace access mode <strong>PTRACE_MODE_READ_REALCREDS</strong> check on older Linux versions; see <strong>ptrace</strong>(2).</p>
<p>The <em>group_fd</em> argument allows event groups to be created. An event group has one event which is the group leader. The leader is created first, with <em>group_fd</em> = -1. The rest of the group members are created with subsequent <strong>perf_event_open</strong>() calls with <em>group_fd</em> being set to the file descriptor of the group leader. (A single event on its own is created with <em>group_fd</em> = -1 and is considered to be a group with only 1 member.) An event group is scheduled onto the CPU as a unit: it will be put onto the CPU only if all of the events in the group can be put onto the CPU. This means that the values of the member events can be meaningfully compared—added, divided (to get ratios), and so on—with each other, since they have counted events for the same set of executed instructions.</p>
<p>The <em>flags</em> argument is formed by ORing together zero or more of the following values:</p>
<dl>
<dt><strong>PERF_FLAG_FD_CLOEXEC</strong> (since Linux 3.14)</dt>
<dd><p>This flag enables the close-on-exec flag for the created event file descriptor, so that the file descriptor is automatically closed on <strong>execve</strong>(2). Setting the close-on-exec flags at creation time, rather than later with <strong>fcntl</strong>(2), avoids potential race conditions where the calling thread invokes <strong>perf_event_open</strong>() and <strong>fcntl</strong>(2) at the same time as another thread calls <strong>fork</strong>(2) then <strong>execve</strong>(2).</p>
</dd>
<dt><strong>PERF_FLAG_FD_NO_GROUP</strong></dt>
<dd><p>This flag tells the event to ignore the <em>group_fd</em> parameter except for the purpose of setting up output redirection using the <strong>PERF_FLAG_FD_OUTPUT</strong> flag.</p>
</dd>
<dt><strong>PERF_FLAG_FD_OUTPUT</strong> (broken since Linux 2.6.35)</dt>
<dd><p>This flag re-routes the event's sampled output to instead be included in the mmap buffer of the event specified by <em>group_fd</em>.</p>
</dd>
<dt><strong>PERF_FLAG_PID_CGROUP</strong> (since Linux 2.6.39)</dt>
<dd><p>This flag activates per-container system-wide monitoring. A container is an abstraction that isolates a set of resources for finer-grained control (CPUs, memory, etc.). In this mode, the event is measured only if the thread running on the monitored CPU belongs to the designated container (cgroup). The cgroup is identified by passing a file descriptor opened on its directory in the cgroupfs filesystem. For instance, if the cgroup to monitor is called <em>test</em>, then a file descriptor opened on <em>/dev/cgroup/test</em> (assuming cgroupfs is mounted on <em>/dev/cgroup</em>) must be passed as the <em>pid</em> parameter. cgroup monitoring is available only for system-wide events and may therefore require extra permissions.</p>
</dd>
</dl>
<p>The <em>perf_event_attr</em> structure provides detailed configuration information for the event being created.</p>
<pre><code>struct perf_event_attr {
    __u32 type;                 /* Type of event */
    __u32 size;                 /* Size of attribute structure */
    __u64 config;               /* Type-specific configuration */

    union {
        __u64 sample_period;    /* Period of sampling */
        __u64 sample_freq;      /* Frequency of sampling */
    };

    __u64 sample_type;  /* Specifies values included in sample */
    __u64 read_format;  /* Specifies values returned in read */

    __u64 disabled       : 1,   /* off by default */
          inherit        : 1,   /* children inherit it */
          pinned         : 1,   /* must always be on PMU */
          exclusive      : 1,   /* only group on PMU */
          exclude_user   : 1,   /* don&#39;t count user */
          exclude_kernel : 1,   /* don&#39;t count kernel */
          exclude_hv     : 1,   /* don&#39;t count hypervisor */
          exclude_idle   : 1,   /* don&#39;t count when idle */
          mmap           : 1,   /* include mmap data */
          comm           : 1,   /* include comm data */
          freq           : 1,   /* use freq, not period */
          inherit_stat   : 1,   /* per task counts */
          enable_on_exec : 1,   /* next exec enables */
          task           : 1,   /* trace fork/exit */
          watermark      : 1,   /* wakeup_watermark */
          precise_ip     : 2,   /* skid constraint */
          mmap_data      : 1,   /* non-exec mmap data */
          sample_id_all  : 1,   /* sample_type all events */
          exclude_host   : 1,   /* don&#39;t count in host */
          exclude_guest  : 1,   /* don&#39;t count in guest */
          exclude_callchain_kernel : 1,
                                /* exclude kernel callchains */
          exclude_callchain_user   : 1,
                                /* exclude user callchains */
          mmap2          :  1,  /* include mmap with inode data */
          comm_exec      :  1,  /* flag comm events that are
                                   due to exec */
          use_clockid    :  1,  /* use clockid for time fields */
          context_switch :  1,  /* context switch data */
          write_backward :  1,  /* Write ring buffer from end
                                   to beginning */
          namespaces     :  1,  /* include namespaces data */
          ksymbol        :  1,  /* include ksymbol events */
          bpf_event      :  1,  /* include bpf events */
          aux_output     :  1,  /* generate AUX records
                                   instead of events */
          cgroup         :  1,  /* include cgroup events */
          text_poke      :  1,  /* include text poke events */

          __reserved_1   : 30;

    union {
        __u32 wakeup_events;    /* wakeup every n events */
        __u32 wakeup_watermark; /* bytes before wakeup */
    };

    __u32     bp_type;          /* breakpoint type */

    union {
        __u64 bp_addr;          /* breakpoint address */
        __u64 kprobe_func;      /* for perf_kprobe */
        __u64 uprobe_path;      /* for perf_uprobe */
        __u64 config1;          /* extension of config */
    };

    union {
        __u64 bp_len;           /* breakpoint length */
        __u64 kprobe_addr;      /* with kprobe_func == NULL */
        __u64 probe_offset;     /* for perf_[k,u]probe */
        __u64 config2;          /* extension of config1 */
    };
    __u64 branch_sample_type;   /* enum perf_branch_sample_type */
    __u64 sample_regs_user;     /* user regs to dump on samples */
    __u32 sample_stack_user;    /* size of stack to dump on
                                   samples */
    __s32 clockid;              /* clock to use for time fields */
    __u64 sample_regs_intr;     /* regs to dump on samples */
    __u32 aux_watermark;        /* aux bytes before wakeup */
    __u16 sample_max_stack;     /* max frames in callchain */
    __u16 __reserved_2;         /* align to u64 */

};</code></pre>
<p>The fields of the <em>perf_event_attr</em> structure are described in more detail below:</p>
<dl>
<dt><em>type</em></dt>
<dd><p>This field specifies the overall event type. It has one of the following values:</p>
<dl>
<dt><strong>PERF_TYPE_HARDWARE</strong></dt>
<dd><p>This indicates one of the "generalized" hardware events provided by the kernel. See the <em>config</em> field definition for more details.</p>
</dd>
<dt><strong>PERF_TYPE_SOFTWARE</strong></dt>
<dd><p>This indicates one of the software-defined events provided by the kernel (even if no hardware support is available).</p>
</dd>
<dt><strong>PERF_TYPE_TRACEPOINT</strong></dt>
<dd><p>This indicates a tracepoint provided by the kernel tracepoint infrastructure.</p>
</dd>
<dt><strong>PERF_TYPE_HW_CACHE</strong></dt>
<dd><p>This indicates a hardware cache event. This has a special encoding, described in the <em>config</em> field definition.</p>
</dd>
<dt><strong>PERF_TYPE_RAW</strong></dt>
<dd><p>This indicates a "raw" implementation-specific event in the <em>config</em> field.</p>
</dd>
<dt><strong>PERF_TYPE_BREAKPOINT</strong> (since Linux 2.6.33)</dt>
<dd><p>This indicates a hardware breakpoint as provided by the CPU. Breakpoints can be read/write accesses to an address as well as execution of an instruction address.</p>
</dd>
<dt>dynamic PMU</dt>
<dd><p>Since Linux 2.6.38, <strong>perf_event_open</strong>() can support multiple PMUs. To enable this, a value exported by the kernel can be used in the <em>type</em> field to indicate which PMU to use. The value to use can be found in the sysfs filesystem: there is a subdirectory per PMU instance under <em>/sys/bus/event_source/devices</em>. In each subdirectory there is a <em>type</em> file whose content is an integer that can be used in the <em>type</em> field. For instance, <em>/sys/bus/event_source/devices/cpu/type</em> contains the value for the core CPU PMU, which is usually 4.</p>
</dd>
<dt><strong>kprobe</strong> and <strong>uprobe</strong> (since Linux 4.17)</dt>
<dd><p>These two dynamic PMUs create a kprobe/uprobe and attach it to the file descriptor generated by perf_event_open. The kprobe/uprobe will be destroyed on the destruction of the file descriptor. See fields <em>kprobe_func</em>, <em>uprobe_path</em>, <em>kprobe_addr</em>, and <em>probe_offset</em> for more details.</p>
</dd>
</dl>
</dd>
<dt><em>size</em></dt>
<dd><p>The size of the <em>perf_event_attr</em> structure for forward/backward compatibility. Set this using <em>sizeof(struct perf_event_attr)</em> to allow the kernel to see the struct size at the time of compilation.</p>
<p>The related define <strong>PERF_ATTR_SIZE_VER0</strong> is set to 64; this was the size of the first published struct. <strong>PERF_ATTR_SIZE_VER1</strong> is 72, corresponding to the addition of breakpoints in Linux 2.6.33. <strong>PERF_ATTR_SIZE_VER2</strong> is 80 corresponding to the addition of branch sampling in Linux 3.4. <strong>PERF_ATTR_SIZE_VER3</strong> is 96 corresponding to the addition of <em>sample_regs_user</em> and <em>sample_stack_user</em> in Linux 3.7. <strong>PERF_ATTR_SIZE_VER4</strong> is 104 corresponding to the addition of <em>sample_regs_intr</em> in Linux 3.19. <strong>PERF_ATTR_SIZE_VER5</strong> is 112 corresponding to the addition of <em>aux_watermark</em> in Linux 4.1.</p>
</dd>
<dt><em>config</em></dt>
<dd><p>This specifies which event you want, in conjunction with the <em>type</em> field. The <em>config1</em> and <em>config2</em> fields are also taken into account in cases where 64 bits is not enough to fully specify the event. The encoding of these fields are event dependent.</p>
<p>There are various ways to set the <em>config</em> field that are dependent on the value of the previously described <em>type</em> field. What follows are various possible settings for <em>config</em> separated out by <em>type</em>.</p>
<p>If <em>type</em> is <strong>PERF_TYPE_HARDWARE</strong>, we are measuring one of the generalized hardware CPU events. Not all of these are available on all platforms. Set <em>config</em> to one of the following:</p>
<dl>
<dt><strong>PERF_COUNT_HW_CPU_CYCLES</strong></dt>
<dd><p>Total cycles. Be wary of what happens during CPU frequency scaling.</p>
</dd>
<dt><strong>PERF_COUNT_HW_INSTRUCTIONS</strong></dt>
<dd><p>Retired instructions. Be careful, these can be affected by various issues, most notably hardware interrupt counts.</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_REFERENCES</strong></dt>
<dd><p>Cache accesses. Usually this indicates Last Level Cache accesses but this may vary depending on your CPU. This may include prefetches and coherency messages; again this depends on the design of your CPU.</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_MISSES</strong></dt>
<dd><p>Cache misses. Usually this indicates Last Level Cache misses; this is intended to be used in conjunction with the <strong>PERF_COUNT_HW_CACHE_REFERENCES</strong> event to calculate cache miss rates.</p>
</dd>
<dt><strong>PERF_COUNT_HW_BRANCH_INSTRUCTIONS</strong></dt>
<dd><p>Retired branch instructions. Prior to Linux 2.6.35, this used the wrong event on AMD processors.</p>
</dd>
<dt><strong>PERF_COUNT_HW_BRANCH_MISSES</strong></dt>
<dd><p>Mispredicted branch instructions.</p>
</dd>
<dt><strong>PERF_COUNT_HW_BUS_CYCLES</strong></dt>
<dd><p>Bus cycles, which can be different from total cycles.</p>
</dd>
<dt><strong>PERF_COUNT_HW_STALLED_CYCLES_FRONTEND</strong> (since Linux 3.0)</dt>
<dd><p>Stalled cycles during issue.</p>
</dd>
<dt><strong>PERF_COUNT_HW_STALLED_CYCLES_BACKEND</strong> (since Linux 3.0)</dt>
<dd><p>Stalled cycles during retirement.</p>
</dd>
<dt><strong>PERF_COUNT_HW_REF_CPU_CYCLES</strong> (since Linux 3.3)</dt>
<dd><p>Total cycles; not affected by CPU frequency scaling.</p>
</dd>
</dl>
<p>If <em>type</em> is <strong>PERF_TYPE_SOFTWARE</strong>, we are measuring software events provided by the kernel. Set <em>config</em> to one of the following:</p>
<dl>
<dt><strong>PERF_COUNT_SW_CPU_CLOCK</strong></dt>
<dd><p>This reports the CPU clock, a high-resolution per-CPU timer.</p>
</dd>
<dt><strong>PERF_COUNT_SW_TASK_CLOCK</strong></dt>
<dd><p>This reports a clock count specific to the task that is running.</p>
</dd>
<dt><strong>PERF_COUNT_SW_PAGE_FAULTS</strong></dt>
<dd><p>This reports the number of page faults.</p>
</dd>
<dt><strong>PERF_COUNT_SW_CONTEXT_SWITCHES</strong></dt>
<dd><p>This counts context switches. Until Linux 2.6.34, these were all reported as user-space events, after that they are reported as happening in the kernel.</p>
</dd>
<dt><strong>PERF_COUNT_SW_CPU_MIGRATIONS</strong></dt>
<dd><p>This reports the number of times the process has migrated to a new CPU.</p>
</dd>
<dt><strong>PERF_COUNT_SW_PAGE_FAULTS_MIN</strong></dt>
<dd><p>This counts the number of minor page faults. These did not require disk I/O to handle.</p>
</dd>
<dt><strong>PERF_COUNT_SW_PAGE_FAULTS_MAJ</strong></dt>
<dd><p>This counts the number of major page faults. These required disk I/O to handle.</p>
</dd>
<dt><strong>PERF_COUNT_SW_ALIGNMENT_FAULTS</strong> (since Linux 2.6.33)</dt>
<dd><p>This counts the number of alignment faults. These happen when unaligned memory accesses happen; the kernel can handle these but it reduces performance. This happens only on some architectures (never on x86).</p>
</dd>
<dt><strong>PERF_COUNT_SW_EMULATION_FAULTS</strong> (since Linux 2.6.33)</dt>
<dd><p>This counts the number of emulation faults. The kernel sometimes traps on unimplemented instructions and emulates them for user space. This can negatively impact performance.</p>
</dd>
<dt><strong>PERF_COUNT_SW_DUMMY</strong> (since Linux 3.12)</dt>
<dd><p>This is a placeholder event that counts nothing. Informational sample record types such as mmap or comm must be associated with an active event. This dummy event allows gathering such records without requiring a counting event.</p>
</dd>
</dl>
</dd>
</dl>
<blockquote>
<p>If <em>type</em> is <strong>PERF_TYPE_TRACEPOINT</strong>, then we are measuring kernel tracepoints. The value to use in <em>config</em> can be obtained from under debugfs <em>tracing/events/*/*/id</em> if ftrace is enabled in the kernel.</p>
</blockquote>
<blockquote>
<p>If <em>type</em> is <strong>PERF_TYPE_HW_CACHE</strong>, then we are measuring a hardware CPU cache event. To calculate the appropriate <em>config</em> value, use the following equation:</p>
<blockquote>
<pre><code>config = (perf_hw_cache_id) |
         (perf_hw_cache_op_id &lt;&lt; 8) |
         (perf_hw_cache_op_result_id &lt;&lt; 16);</code></pre>
<p>where <em>perf_hw_cache_id</em> is one of:</p>
<blockquote>
<dl>
<dt><strong>PERF_COUNT_HW_CACHE_L1D</strong></dt>
<dd><p>for measuring Level 1 Data Cache</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_L1I</strong></dt>
<dd><p>for measuring Level 1 Instruction Cache</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_LL</strong></dt>
<dd><p>for measuring Last-Level Cache</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_DTLB</strong></dt>
<dd><p>for measuring the Data TLB</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_ITLB</strong></dt>
<dd><p>for measuring the Instruction TLB</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_BPU</strong></dt>
<dd><p>for measuring the branch prediction unit</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_NODE</strong> (since Linux 3.1)</dt>
<dd><p>for measuring local memory accesses</p>
</dd>
</dl>
</blockquote>
<p>and <em>perf_hw_cache_op_id</em> is one of:</p>
<blockquote>
<dl>
<dt><strong>PERF_COUNT_HW_CACHE_OP_READ</strong></dt>
<dd><p>for read accesses</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_OP_WRITE</strong></dt>
<dd><p>for write accesses</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_OP_PREFETCH</strong></dt>
<dd><p>for prefetch accesses</p>
</dd>
</dl>
</blockquote>
<p>and <em>perf_hw_cache_op_result_id</em> is one of:</p>
<blockquote>
<dl>
<dt><strong>PERF_COUNT_HW_CACHE_RESULT_ACCESS</strong></dt>
<dd><p>to measure accesses</p>
</dd>
<dt><strong>PERF_COUNT_HW_CACHE_RESULT_MISS</strong></dt>
<dd><p>to measure misses</p>
</dd>
</dl>
</blockquote>
</blockquote>
<p>If <em>type</em> is <strong>PERF_TYPE_RAW</strong>, then a custom "raw" <em>config</em> value is needed. Most CPUs support events that are not covered by the "generalized" events. These are implementation defined; see your CPU manual (for example the Intel Volume 3B documentation or the AMD BIOS and Kernel Developer Guide). The libpfm4 library can be used to translate from the name in the architectural manuals to the raw hex value <strong>perf_event_open</strong>() expects in this field.</p>
<p>If <em>type</em> is <strong>PERF_TYPE_BREAKPOINT</strong>, then leave <em>config</em> set to zero. Its parameters are set in other places.</p>
<p>If <em>type</em> is <strong>kprobe</strong> or <strong>uprobe</strong>, set <em>retprobe</em> (bit 0 of <em>config</em>, see <em>/sys/bus/event_source/devices/[k,u]probe/format/retprobe</em>) for kretprobe/uretprobe. See fields <em>kprobe_func</em>, <em>uprobe_path</em>, <em>kprobe_addr</em>, and <em>probe_offset</em> for more details.</p>
</blockquote>
<dl>
<dt><em>kprobe_func</em>, <em>uprobe_path</em>, <em>kprobe_addr</em>, and <em>probe_offset</em></dt>
<dd><p>These fields describe the kprobe/uprobe for dynamic PMUs <strong>kprobe</strong> and <strong>uprobe</strong>. For <strong>kprobe</strong>: use <em>kprobe_func</em> and <em>probe_offset</em>, or use <em>kprobe_addr</em> and leave <em>kprobe_func</em> as NULL. For <strong>uprobe</strong>: use <em>uprobe_path</em> and <em>probe_offset</em>.</p>
</dd>
<dt><em>sample_period</em>, <em>sample_freq</em></dt>
<dd><p>A "sampling" event is one that generates an overflow notification every N events, where N is given by <em>sample_period</em>. A sampling event has <em>sample_period</em> &gt; 0. When an overflow occurs, requested data is recorded in the mmap buffer. The <em>sample_type</em> field controls what data is recorded on each overflow.</p>
<p><em>sample_freq</em> can be used if you wish to use frequency rather than period. In this case, you set the <em>freq</em> flag. The kernel will adjust the sampling period to try and achieve the desired rate. The rate of adjustment is a timer tick.</p>
</dd>
<dt><em>sample_type</em></dt>
<dd><p>The various bits in this field specify which values to include in the sample. They will be recorded in a ring-buffer, which is available to user space using <strong>mmap</strong>(2). The order in which the values are saved in the sample are documented in the MMAP Layout subsection below; it is not the <em>enum perf_event_sample_format</em> order.</p>
<dl>
<dt><strong>PERF_SAMPLE_IP</strong></dt>
<dd><p>Records instruction pointer.</p>
</dd>
<dt><strong>PERF_SAMPLE_TID</strong></dt>
<dd><p>Records the process and thread IDs.</p>
</dd>
<dt><strong>PERF_SAMPLE_TIME</strong></dt>
<dd><p>Records a timestamp.</p>
</dd>
<dt><strong>PERF_SAMPLE_ADDR</strong></dt>
<dd><p>Records an address, if applicable.</p>
</dd>
<dt><strong>PERF_SAMPLE_READ</strong></dt>
<dd><p>Record counter values for all events in a group, not just the group leader.</p>
</dd>
<dt><strong>PERF_SAMPLE_CALLCHAIN</strong></dt>
<dd><p>Records the callchain (stack backtrace).</p>
</dd>
<dt><strong>PERF_SAMPLE_ID</strong></dt>
<dd><p>Records a unique ID for the opened event's group leader.</p>
</dd>
<dt><strong>PERF_SAMPLE_CPU</strong></dt>
<dd><p>Records CPU number.</p>
</dd>
<dt><strong>PERF_SAMPLE_PERIOD</strong></dt>
<dd><p>Records the current sampling period.</p>
</dd>
<dt><strong>PERF_SAMPLE_STREAM_ID</strong></dt>
<dd><p>Records a unique ID for the opened event. Unlike <strong>PERF_SAMPLE_ID</strong> the actual ID is returned, not the group leader. This ID is the same as the one returned by <strong>PERF_FORMAT_ID</strong>.</p>
</dd>
<dt><strong>PERF_SAMPLE_RAW</strong></dt>
<dd><p>Records additional data, if applicable. Usually returned by tracepoint events.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_STACK</strong> (since Linux 3.4)</dt>
<dd><p>This provides a record of recent branches, as provided by CPU branch sampling hardware (such as Intel Last Branch Record). Not all hardware supports this feature.</p>
<p>See the <em>branch_sample_type</em> field for how to filter which branches are reported.</p>
</dd>
<dt><strong>PERF_SAMPLE_REGS_USER</strong> (since Linux 3.7)</dt>
<dd><p>Records the current user-level CPU register state (the values in the process before the kernel was called).</p>
</dd>
<dt><strong>PERF_SAMPLE_STACK_USER</strong> (since Linux 3.7)</dt>
<dd><p>Records the user level stack, allowing stack unwinding.</p>
</dd>
<dt><strong>PERF_SAMPLE_WEIGHT</strong> (since Linux 3.10)</dt>
<dd><p>Records a hardware provided weight value that expresses how costly the sampled event was. This allows the hardware to highlight expensive events in a profile.</p>
</dd>
<dt><strong>PERF_SAMPLE_DATA_SRC</strong> (since Linux 3.10)</dt>
<dd><p>Records the data source: where in the memory hierarchy the data associated with the sampled instruction came from. This is available only if the underlying hardware supports this feature.</p>
</dd>
<dt><strong>PERF_SAMPLE_IDENTIFIER</strong> (since Linux 3.12)</dt>
<dd><p>Places the <strong>SAMPLE_ID</strong> value in a fixed position in the record, either at the beginning (for sample events) or at the end (if a non-sample event).</p>
<p>This was necessary because a sample stream may have records from various different event sources with different <em>sample_type</em> settings. Parsing the event stream properly was not possible because the format of the record was needed to find <strong>SAMPLE_ID</strong>, but the format could not be found without knowing what event the sample belonged to (causing a circular dependency).</p>
<p>The <strong>PERF_SAMPLE_IDENTIFIER</strong> setting makes the event stream always parsable by putting <strong>SAMPLE_ID</strong> in a fixed location, even though it means having duplicate <strong>SAMPLE_ID</strong> values in records.</p>
</dd>
<dt><strong>PERF_SAMPLE_TRANSACTION</strong> (since Linux 3.13)</dt>
<dd><p>Records reasons for transactional memory abort events (for example, from Intel TSX transactional memory support).</p>
<p>The <em>precise_ip</em> setting must be greater than 0 and a transactional memory abort event must be measured or no values will be recorded. Also note that some perf_event measurements, such as sampled cycle counting, may cause extraneous aborts (by causing an interrupt during a transaction).</p>
</dd>
<dt><strong>PERF_SAMPLE_REGS_INTR</strong> (since Linux 3.19)</dt>
<dd><p>Records a subset of the current CPU register state as specified by <em>sample_regs_intr</em>. Unlike <strong>PERF_SAMPLE_REGS_USER</strong> the register values will return kernel register state if the overflow happened while kernel code is running. If the CPU supports hardware sampling of register state (i.e., PEBS on Intel x86) and <em>precise_ip</em> is set higher than zero then the register values returned are those captured by hardware at the time of the sampled instruction's retirement.</p>
</dd>
<dt><strong>PERF_SAMPLE_PHYS_ADDR</strong> (since Linux 4.13)</dt>
<dd><p>Records physical address of data like in <strong>PERF_SAMPLE_ADDR</strong>.</p>
</dd>
<dt><strong>PERF_SAMPLE_CGROUP</strong> (since Linux 5.7)</dt>
<dd><p>Records (perf_event) cgroup ID of the process. This corresponds to the <em>id</em> field in the <strong>PERF_RECORD_CGROUP</strong> event.</p>
</dd>
</dl>
</dd>
<dt><em>read_format</em></dt>
<dd><p>This field specifies the format of the data returned by <strong>read</strong>(2) on a <strong>perf_event_open</strong>() file descriptor.</p>
<dl>
<dt><strong>PERF_FORMAT_TOTAL_TIME_ENABLED</strong></dt>
<dd><p>Adds the 64-bit <em>time_enabled</em> field. This can be used to calculate estimated totals if the PMU is overcommitted and multiplexing is happening.</p>
</dd>
<dt><strong>PERF_FORMAT_TOTAL_TIME_RUNNING</strong></dt>
<dd><p>Adds the 64-bit <em>time_running</em> field. This can be used to calculate estimated totals if the PMU is overcommitted and multiplexing is happening.</p>
</dd>
<dt><strong>PERF_FORMAT_ID</strong></dt>
<dd><p>Adds a 64-bit unique value that corresponds to the event group.</p>
</dd>
<dt><strong>PERF_FORMAT_GROUP</strong></dt>
<dd><p>Allows all counter values in an event group to be read with one read.</p>
</dd>
</dl>
</dd>
<dt><em>disabled</em></dt>
<dd><p>The <em>disabled</em> bit specifies whether the counter starts out disabled or enabled. If disabled, the event can later be enabled by <strong>ioctl</strong>(2), <strong>prctl</strong>(2), or <em>enable_on_exec</em>.</p>
<p>When creating an event group, typically the group leader is initialized with <em>disabled</em> set to 1 and any child events are initialized with <em>disabled</em> set to 0. Despite <em>disabled</em> being 0, the child events will not start until the group leader is enabled.</p>
</dd>
<dt><em>inherit</em></dt>
<dd><p>The <em>inherit</em> bit specifies that this counter should count events of child tasks as well as the task specified. This applies only to new children, not to any existing children at the time the counter is created (nor to any new children of existing children).</p>
<p>Inherit does not work for some combinations of <em>read_format</em> values, such as <strong>PERF_FORMAT_GROUP</strong>.</p>
</dd>
<dt><em>pinned</em></dt>
<dd><p>The <em>pinned</em> bit specifies that the counter should always be on the CPU if at all possible. It applies only to hardware counters and only to group leaders. If a pinned counter cannot be put onto the CPU (e.g., because there are not enough hardware counters or because of a conflict with some other event), then the counter goes into an 'error' state, where reads return end-of-file (i.e., <strong>read</strong>(2) returns 0) until the counter is subsequently enabled or disabled.</p>
</dd>
<dt><em>exclusive</em></dt>
<dd><p>The <em>exclusive</em> bit specifies that when this counter's group is on the CPU, it should be the only group using the CPU's counters. In the future this may allow monitoring programs to support PMU features that need to run alone so that they do not disrupt other hardware counters.</p>
<p>Note that many unexpected situations may prevent events with the <em>exclusive</em> bit set from ever running. This includes any users running a system-wide measurement as well as any kernel use of the performance counters (including the commonly enabled NMI Watchdog Timer interface).</p>
</dd>
<dt><em>exclude_user</em></dt>
<dd><p>If this bit is set, the count excludes events that happen in user space.</p>
</dd>
<dt><em>exclude_kernel</em></dt>
<dd><p>If this bit is set, the count excludes events that happen in kernel space.</p>
</dd>
<dt><em>exclude_hv</em></dt>
<dd><p>If this bit is set, the count excludes events that happen in the hypervisor. This is mainly for PMUs that have built-in support for handling this (such as POWER). Extra support is needed for handling hypervisor measurements on most machines.</p>
</dd>
<dt><em>exclude_idle</em></dt>
<dd><p>If set, don't count when the CPU is running the idle task. While you can currently enable this for any event type, it is ignored for all but software events.</p>
</dd>
<dt><em>mmap</em></dt>
<dd><p>The <em>mmap</em> bit enables generation of <strong>PERF_RECORD_MMAP</strong> samples for every <strong>mmap</strong>(2) call that has <strong>PROT_EXEC</strong> set. This allows tools to notice new executable code being mapped into a program (dynamic shared libraries for example) so that addresses can be mapped back to the original code.</p>
</dd>
<dt><em>comm</em></dt>
<dd><p>The <em>comm</em> bit enables tracking of process command name as modified by the <strong>exec</strong>(2) and <strong>prctl</strong>(PR_SET_NAME) system calls as well as writing to <em>/proc/self/comm</em>. If the <em>comm_exec</em> flag is also successfully set (possible since Linux 3.16), then the misc flag <strong>PERF_RECORD_MISC_COMM_EXEC</strong> can be used to differentiate the <strong>exec</strong>(2) case from the others.</p>
</dd>
<dt><em>freq</em></dt>
<dd><p>If this bit is set, then <em>sample_frequency</em> not <em>sample_period</em> is used when setting up the sampling interval.</p>
</dd>
<dt><em>inherit_stat</em></dt>
<dd><p>This bit enables saving of event counts on context switch for inherited tasks. This is meaningful only if the <em>inherit</em> field is set.</p>
</dd>
<dt><em>enable_on_exec</em></dt>
<dd><p>If this bit is set, a counter is automatically enabled after a call to <strong>exec</strong>(2).</p>
</dd>
<dt><em>task</em></dt>
<dd><p>If this bit is set, then fork/exit notifications are included in the ring buffer.</p>
</dd>
<dt><em>watermark</em></dt>
<dd><p>If set, have an overflow notification happen when we cross the <em>wakeup_watermark</em> boundary. Otherwise, overflow notifications happen after <em>wakeup_events</em> samples.</p>
</dd>
<dt><em>precise_ip</em> (since Linux 2.6.35)</dt>
<dd><p>This controls the amount of skid. Skid is how many instructions execute between an event of interest happening and the kernel being able to stop and record the event. Smaller skid is better and allows more accurate reporting of which events correspond to which instructions, but hardware is often limited with how small this can be.</p>
<p>The possible values of this field are the following:</p>
<ol start="0" type="1">
<li><p><strong>SAMPLE_IP</strong> can have arbitrary skid.</p></li>
<li><p><strong>SAMPLE_IP</strong> must have constant skid.</p></li>
<li><p><strong>SAMPLE_IP</strong> requested to have 0 skid.</p></li>
<li><p><strong>SAMPLE_IP</strong> must have 0 skid. See also the description of <strong>PERF_RECORD_MISC_EXACT_IP</strong>.</p></li>
</ol>
</dd>
<dt><em>mmap_data</em> (since Linux 2.6.36)</dt>
<dd><p>This is the counterpart of the <em>mmap</em> field. This enables generation of <strong>PERF_RECORD_MMAP</strong> samples for <strong>mmap</strong>(2) calls that do not have <strong>PROT_EXEC</strong> set (for example data and SysV shared memory).</p>
</dd>
<dt><em>sample_id_all</em> (since Linux 2.6.38)</dt>
<dd><p>If set, then TID, TIME, ID, STREAM_ID, and CPU can additionally be included in non-<strong>PERF_RECORD_SAMPLE</strong>s if the corresponding <em>sample_type</em> is selected.</p>
<p>If <strong>PERF_SAMPLE_IDENTIFIER</strong> is specified, then an additional ID value is included as the last value to ease parsing the record stream. This may lead to the <em>id</em> value appearing twice.</p>
<p>The layout is described by this pseudo-structure:</p>
<pre><code>struct sample_id {
    { u32 pid, tid; }   /* if PERF_SAMPLE_TID set */
    { u64 time;     }   /* if PERF_SAMPLE_TIME set */
    { u64 id;       }   /* if PERF_SAMPLE_ID set */
    { u64 stream_id;}   /* if PERF_SAMPLE_STREAM_ID set  */
    { u32 cpu, res; }   /* if PERF_SAMPLE_CPU set */
    { u64 id;       }   /* if PERF_SAMPLE_IDENTIFIER set */
};</code></pre>
</dd>
<dt><em>exclude_host</em> (since Linux 3.2)</dt>
<dd><p>When conducting measurements that include processes running VM instances (i.e., have executed a <strong>KVM_RUN</strong> <strong>ioctl</strong>(2)), only measure events happening inside a guest instance. This is only meaningful outside the guests; this setting does not change counts gathered inside of a guest. Currently, this functionality is x86 only.</p>
</dd>
<dt><em>exclude_guest</em> (since Linux 3.2)</dt>
<dd><p>When conducting measurements that include processes running VM instances (i.e., have executed a <strong>KVM_RUN</strong> <strong>ioctl</strong>(2)), do not measure events happening inside guest instances. This is only meaningful outside the guests; this setting does not change counts gathered inside of a guest. Currently, this functionality is x86 only.</p>
</dd>
<dt><em>exclude_callchain_kernel</em> (since Linux 3.7)</dt>
<dd><p>Do not include kernel callchains.</p>
</dd>
<dt><em>exclude_callchain_user</em> (since Linux 3.7)</dt>
<dd><p>Do not include user callchains.</p>
</dd>
<dt><em>mmap2</em> (since Linux 3.16)</dt>
<dd><p>Generate an extended executable mmap record that contains enough additional information to uniquely identify shared mappings. The <em>mmap</em> flag must also be set for this to work.</p>
</dd>
<dt><em>comm_exec</em> (since Linux 3.16)</dt>
<dd><p>This is purely a feature-detection flag, it does not change kernel behavior. If this flag can successfully be set, then, when <em>comm</em> is enabled, the <strong>PERF_RECORD_MISC_COMM_EXEC</strong> flag will be set in the <em>misc</em> field of a comm record header if the rename event being reported was caused by a call to <strong>exec</strong>(2). This allows tools to distinguish between the various types of process renaming.</p>
</dd>
<dt><em>use_clockid</em> (since Linux 4.1)</dt>
<dd><p>This allows selecting which internal Linux clock to use when generating timestamps via the <em>clockid</em> field. This can make it easier to correlate perf sample times with timestamps generated by other tools.</p>
</dd>
<dt><em>context_switch</em> (since Linux 4.3)</dt>
<dd><p>This enables the generation of <strong>PERF_RECORD_SWITCH</strong> records when a context switch occurs. It also enables the generation of <strong>PERF_RECORD_SWITCH_CPU_WIDE</strong> records when sampling in CPU-wide mode. This functionality is in addition to existing tracepoint and software events for measuring context switches. The advantage of this method is that it will give full information even with strict <em>perf_event_paranoid</em> settings.</p>
</dd>
<dt><em>write_backward</em> (since Linux 4.6)</dt>
<dd><p>This causes the ring buffer to be written from the end to the beginning. This is to support reading from overwritable ring buffer.</p>
</dd>
<dt><em>namespaces</em> (since Linux 4.11)</dt>
<dd><p>This enables the generation of <strong>PERF_RECORD_NAMESPACES</strong> records when a task enters a new namespace. Each namespace has a combination of device and inode numbers.</p>
</dd>
<dt><em>ksymbol</em> (since Linux 5.0)</dt>
<dd><p>This enables the generation of <strong>PERF_RECORD_KSYMBOL</strong> records when new kernel symbols are registered or unregistered. This is analyzing dynamic kernel functions like eBPF.</p>
</dd>
<dt><em>bpf_event</em> (since Linux 5.0)</dt>
<dd><p>This enables the generation of <strong>PERF_RECORD_BPF_EVENT</strong> records when an eBPF program is loaded or unloaded.</p>
</dd>
<dt><em>auxevent</em> (since Linux 5.4)</dt>
<dd><p>This allows normal (non-AUX) events to generate data for AUX events if the hardware supports it.</p>
</dd>
<dt><em>cgroup</em> (since Linux 5.7)</dt>
<dd><p>This enables the generation of <strong>PERF_RECORD_CGROUP</strong> records when a new cgroup is created (and activated).</p>
</dd>
<dt><em>text_poke</em> (since Linux 5.8)</dt>
<dd><p>This enables the generation of <strong>PERF_RECORD_TEXT_POKE</strong> records when there's a changes to the kernel text (i.e., self-modifying code).</p>
</dd>
<dt><em>wakeup_events</em>, <em>wakeup_watermark</em></dt>
<dd><p>This union sets how many samples (<em>wakeup_events</em>) or bytes (<em>wakeup_watermark</em>) happen before an overflow notification happens. Which one is used is selected by the <em>watermark</em> bit flag.</p>
<p><em>wakeup_events</em> counts only <strong>PERF_RECORD_SAMPLE</strong> record types. To receive overflow notification for all <strong>PERF_RECORD</strong> types choose watermark and set <em>wakeup_watermark</em> to 1.</p>
<p>Prior to Linux 3.0, setting <em>wakeup_events</em> to 0 resulted in no overflow notifications; more recent kernels treat 0 the same as 1.</p>
</dd>
<dt><em>bp_type</em> (since Linux 2.6.33)</dt>
<dd><p>This chooses the breakpoint type. It is one of:</p>
<dl>
<dt><strong>HW_BREAKPOINT_EMPTY</strong></dt>
<dd><p>No breakpoint.</p>
</dd>
<dt><strong>HW_BREAKPOINT_R</strong></dt>
<dd><p>Count when we read the memory location.</p>
</dd>
<dt><strong>HW_BREAKPOINT_W</strong></dt>
<dd><p>Count when we write the memory location.</p>
</dd>
<dt><strong>HW_BREAKPOINT_RW</strong></dt>
<dd><p>Count when we read or write the memory location.</p>
</dd>
<dt><strong>HW_BREAKPOINT_X</strong></dt>
<dd><p>Count when we execute code at the memory location.</p>
</dd>
</dl>
<p>The values can be combined via a bitwise or, but the combination of <strong>HW_BREAKPOINT_R</strong> or <strong>HW_BREAKPOINT_W</strong> with <strong>HW_BREAKPOINT_X</strong> is not allowed.</p>
</dd>
<dt><em>bp_addr</em> (since Linux 2.6.33)</dt>
<dd><p>This is the address of the breakpoint. For execution breakpoints, this is the memory address of the instruction of interest; for read and write breakpoints, it is the memory address of the memory location of interest.</p>
</dd>
<dt><em>config1</em> (since Linux 2.6.39)</dt>
<dd><p><em>config1</em> is used for setting events that need an extra register or otherwise do not fit in the regular config field. Raw OFFCORE_EVENTS on Nehalem/Westmere/SandyBridge use this field on Linux 3.3 and later kernels.</p>
</dd>
<dt><em>bp_len</em> (since Linux 2.6.33)</dt>
<dd><p><em>bp_len</em> is the length of the breakpoint being measured if <em>type</em> is <strong>PERF_TYPE_BREAKPOINT</strong>. Options are <strong>HW_BREAKPOINT_LEN_1</strong>, <strong>HW_BREAKPOINT_LEN_2</strong>, <strong>HW_BREAKPOINT_LEN_4</strong>, and <strong>HW_BREAKPOINT_LEN_8</strong>. For an execution breakpoint, set this to <em>sizeof(long)</em>.</p>
</dd>
<dt><em>config2</em> (since Linux 2.6.39)</dt>
<dd><p><em>config2</em> is a further extension of the <em>config1</em> field.</p>
</dd>
<dt><em>branch_sample_type</em> (since Linux 3.4)</dt>
<dd><p>If <strong>PERF_SAMPLE_BRANCH_STACK</strong> is enabled, then this specifies what branches to include in the branch record.</p>
<p>The first part of the value is the privilege level, which is a combination of one of the values listed below. If the user does not set privilege level explicitly, the kernel will use the event's privilege level. Event and branch privilege levels do not have to match.</p>
<dl>
<dt><strong>PERF_SAMPLE_BRANCH_USER</strong></dt>
<dd><p>Branch target is in user space.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_KERNEL</strong></dt>
<dd><p>Branch target is in kernel space.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_HV</strong></dt>
<dd><p>Branch target is in hypervisor.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_PLM_ALL</strong></dt>
<dd><p>A convenience value that is the three preceding values ORed together.</p>
</dd>
</dl>
<p>In addition to the privilege value, at least one or more of the following bits must be set.</p>
<dl>
<dt><strong>PERF_SAMPLE_BRANCH_ANY</strong></dt>
<dd><p>Any branch type.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_ANY_CALL</strong></dt>
<dd><p>Any call branch (includes direct calls, indirect calls, and far jumps).</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_IND_CALL</strong></dt>
<dd><p>Indirect calls.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_CALL</strong> (since Linux 4.4)</dt>
<dd><p>Direct calls.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_ANY_RETURN</strong></dt>
<dd><p>Any return branch.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_IND_JUMP</strong> (since Linux 4.2)</dt>
<dd><p>Indirect jumps.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_COND</strong> (since Linux 3.16)</dt>
<dd><p>Conditional branches.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_ABORT_TX</strong> (since Linux 3.11)</dt>
<dd><p>Transactional memory aborts.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_IN_TX</strong> (since Linux 3.11)</dt>
<dd><p>Branch in transactional memory transaction.</p>
</dd>
<dt><strong>PERF_SAMPLE_BRANCH_NO_TX</strong> (since Linux 3.11)</dt>
<dd><p>Branch not in transactional memory transaction. <strong>PERF_SAMPLE_BRANCH_CALL_STACK</strong> (since Linux 4.1) Branch is part of a hardware-generated call stack. This requires hardware support, currently only found on Intel x86 Haswell or newer.</p>
</dd>
</dl>
</dd>
<dt><em>sample_regs_user</em> (since Linux 3.7)</dt>
<dd><p>This bit mask defines the set of user CPU registers to dump on samples. The layout of the register mask is architecture-specific and is described in the kernel header file <em>arch/ARCH/include/uapi/asm/perf_regs.h</em>.</p>
</dd>
<dt><em>sample_stack_user</em> (since Linux 3.7)</dt>
<dd><p>This defines the size of the user stack to dump if <strong>PERF_SAMPLE_STACK_USER</strong> is specified.</p>
</dd>
<dt><em>clockid</em> (since Linux 4.1)</dt>
<dd><p>If <em>use_clockid</em> is set, then this field selects which internal Linux timer to use for timestamps. The available timers are defined in <em>linux/time.h</em>, with <strong>CLOCK_MONOTONIC</strong>, <strong>CLOCK_MONOTONIC_RAW</strong>, <strong>CLOCK_REALTIME</strong>, <strong>CLOCK_BOOTTIME</strong>, and <strong>CLOCK_TAI</strong> currently supported.</p>
</dd>
<dt><em>aux_watermark</em> (since Linux 4.1)</dt>
<dd><p>This specifies how much data is required to trigger a <strong>PERF_RECORD_AUX</strong> sample.</p>
</dd>
<dt><em>sample_max_stack</em> (since Linux 4.8)</dt>
<dd><p>When <em>sample_type</em> includes <strong>PERF_SAMPLE_CALLCHAIN</strong>, this field specifies how many stack frames to report when generating the callchain.</p>
</dd>
</dl>
<h2>Reading results</h2>
<p>Once a <strong>perf_event_open</strong>() file descriptor has been opened, the values of the events can be read from the file descriptor. The values that are there are specified by the <em>read_format</em> field in the <em>attr</em> structure at open time.</p>
<p>If you attempt to read into a buffer that is not big enough to hold the data, the error <strong>ENOSPC</strong> results.</p>
<p>Here is the layout of the data returned by a read:</p>
<ul>
<li><p>If <strong>PERF_FORMAT_GROUP</strong> was specified to allow reading all events in a group at once:</p>
<pre><code>struct read_format {
    u64 nr;            /* The number of events */
    u64 time_enabled;  /* if PERF_FORMAT_TOTAL_TIME_ENABLED */
    u64 time_running;  /* if PERF_FORMAT_TOTAL_TIME_RUNNING */
    struct {
        u64 value;     /* The value of the event */
        u64 id;        /* if PERF_FORMAT_ID */
    } values[nr];
};</code></pre></li>
<li><p>If <strong>PERF_FORMAT_GROUP</strong> was <em>not</em> specified:</p>
<pre><code>struct read_format {
    u64 value;         /* The value of the event */
    u64 time_enabled;  /* if PERF_FORMAT_TOTAL_TIME_ENABLED */
    u64 time_running;  /* if PERF_FORMAT_TOTAL_TIME_RUNNING */
    u64 id;            /* if PERF_FORMAT_ID */
};</code></pre></li>
</ul>
<p>The values read are as follows:</p>
<dl>
<dt><em>nr</em></dt>
<dd><p>The number of events in this file descriptor. Available only if <strong>PERF_FORMAT_GROUP</strong> was specified.</p>
</dd>
<dt><em>time_enabled</em>, <em>time_running</em></dt>
<dd><p>Total time the event was enabled and running. Normally these values are the same. Multiplexing happens if the number of events is more than the number of available PMU counter slots. In that case the events run only part of the time and the <em>time_enabled</em> and <em>time running</em> values can be used to scale an estimated value for the count.</p>
</dd>
<dt><em>value</em></dt>
<dd><p>An unsigned 64-bit value containing the counter result.</p>
</dd>
<dt><em>id</em></dt>
<dd><p>A globally unique value for this particular event; only present if <strong>PERF_FORMAT_ID</strong> was specified in <em>read_format</em>.</p>
</dd>
</dl>
<h2>MMAP layout</h2>
<p>When using <strong>perf_event_open</strong>() in sampled mode, asynchronous events (like counter overflow or <strong>PROT_EXEC</strong> mmap tracking) are logged into a ring-buffer. This ring-buffer is created and accessed through <strong>mmap</strong>(2).</p>
<p>The mmap size should be 1+2^n pages, where the first page is a metadata page (<em>struct perf_event_mmap_page</em>) that contains various bits of information such as where the ring-buffer head is.</p>
<p>Before kernel 2.6.39, there is a bug that means you must allocate an mmap ring buffer when sampling even if you do not plan to access it.</p>
<p>The structure of the first metadata mmap page is as follows:</p>
<pre><code>struct perf_event_mmap_page {
    __u32 version;        /* version number of this structure */
    __u32 compat_version; /* lowest version this is compat with */
    __u32 lock;           /* seqlock for synchronization */
    __u32 index;          /* hardware counter identifier */
    __s64 offset;         /* add to hardware counter value */
    __u64 time_enabled;   /* time event active */
    __u64 time_running;   /* time event on CPU */
    union {
        __u64   capabilities;
        struct {
            __u64 cap_usr_time / cap_usr_rdpmc / cap_bit0 : 1,
                  cap_bit0_is_deprecated : 1,
                  cap_user_rdpmc         : 1,
                  cap_user_time          : 1,
                  cap_user_time_zero     : 1,
        };
    };
    __u16 pmc_width;
    __u16 time_shift;
    __u32 time_mult;
    __u64 time_offset;
    __u64 __reserved[120];   /* Pad to 1 k */
    __u64 data_head;         /* head in the data section */
    __u64 data_tail;         /* user-space written tail */
    __u64 data_offset;       /* where the buffer starts */
    __u64 data_size;         /* data buffer size */
    __u64 aux_head;
    __u64 aux_tail;
    __u64 aux_offset;
    __u64 aux_size;

}</code></pre>
<p>The following list describes the fields in the <em>perf_event_mmap_page</em> structure in more detail:</p>
<dl>
<dt><em>version</em></dt>
<dd><p>Version number of this structure.</p>
</dd>
<dt><em>compat_version</em></dt>
<dd><p>The lowest version this is compatible with.</p>
</dd>
<dt><em>lock</em></dt>
<dd><p>A seqlock for synchronization.</p>
</dd>
<dt><em>index</em></dt>
<dd><p>A unique hardware counter identifier.</p>
</dd>
<dt><em>offset</em></dt>
<dd><p>When using rdpmc for reads this offset value must be added to the one returned by rdpmc to get the current total event count.</p>
</dd>
<dt><em>time_enabled</em></dt>
<dd><p>Time the event was active.</p>
</dd>
<dt><em>time_running</em></dt>
<dd><p>Time the event was running.</p>
</dd>
<dt><em>cap_usr_time</em> / <em>cap_usr_rdpmc</em> / <em>cap_bit0</em> (since Linux 3.4)</dt>
<dd><p>There was a bug in the definition of <em>cap_usr_time</em> and <em>cap_usr_rdpmc</em> from Linux 3.4 until Linux 3.11. Both bits were defined to point to the same location, so it was impossible to know if <em>cap_usr_time</em> or <em>cap_usr_rdpmc</em> were actually set.</p>
<p>Starting with Linux 3.12, these are renamed to <em>cap_bit0</em> and you should use the <em>cap_user_time</em> and <em>cap_user_rdpmc</em> fields instead.</p>
</dd>
<dt><em>cap_bit0_is_deprecated</em> (since Linux 3.12)</dt>
<dd><p>If set, this bit indicates that the kernel supports the properly separated <em>cap_user_time</em> and <em>cap_user_rdpmc</em> bits.</p>
<p>If not-set, it indicates an older kernel where <em>cap_usr_time</em> and <em>cap_usr_rdpmc</em> map to the same bit and thus both features should be used with caution.</p>
</dd>
<dt><em>cap_user_rdpmc</em> (since Linux 3.12)</dt>
<dd><p>If the hardware supports user-space read of performance counters without syscall (this is the "rdpmc" instruction on x86), then the following code can be used to do a read:</p>
<pre><code>u32 seq, time_mult, time_shift, idx, width;
u64 count, enabled, running;
u64 cyc, time_offset;

do {
    seq = pc-&gt;lock;
    barrier();
    enabled = pc-&gt;time_enabled;
    running = pc-&gt;time_running;

    if (pc-&gt;cap_usr_time &amp;&amp; enabled != running) {
        cyc = rdtsc();
        time_offset = pc-&gt;time_offset;
        time_mult   = pc-&gt;time_mult;
        time_shift  = pc-&gt;time_shift;
    }

    idx = pc-&gt;index;
    count = pc-&gt;offset;

    if (pc-&gt;cap_usr_rdpmc &amp;&amp; idx) {
        width = pc-&gt;pmc_width;
        count += rdpmc(idx - 1);
    }

    barrier();
} while (pc-&gt;lock != seq);</code></pre>
</dd>
<dt><em>cap_user_time</em> (since Linux 3.12)</dt>
<dd><p>This bit indicates the hardware has a constant, nonstop timestamp counter (TSC on x86).</p>
</dd>
<dt><em>cap_user_time_zero</em> (since Linux 3.12)</dt>
<dd><p>Indicates the presence of <em>time_zero</em> which allows mapping timestamp values to the hardware clock.</p>
</dd>
<dt><em>pmc_width</em></dt>
<dd><p>If <em>cap_usr_rdpmc</em>, this field provides the bit-width of the value read using the rdpmc or equivalent instruction. This can be used to sign extend the result like:</p>
<pre><code>pmc &lt;&lt;= 64 - pmc_width;
pmc &gt;&gt;= 64 - pmc_width; // signed shift right
count += pmc;</code></pre>
</dd>
<dt><em>time_shift</em>, <em>time_mult</em>, <em>time_offset</em></dt>
<dd><p>If <em>cap_usr_time</em>, these fields can be used to compute the time delta since <em>time_enabled</em> (in nanoseconds) using rdtsc or similar.</p>
<pre><code>u64 quot, rem;
u64 delta;

quot  = cyc &gt;&gt; time_shift;
rem   = cyc &amp; (((u64)1 &lt;&lt; time_shift) - 1);
delta = time_offset + quot * time_mult +
        ((rem * time_mult) &gt;&gt; time_shift);</code></pre>
<p>Where <em>time_offset</em>, <em>time_mult</em>, <em>time_shift</em>, and <em>cyc</em> are read in the seqcount loop described above. This delta can then be added to enabled and possible running (if idx), improving the scaling:</p>
<pre><code>enabled += delta;
if (idx)
    running += delta;
quot  = count / running;
rem   = count % running;
count = quot * enabled + (rem * enabled) / running;</code></pre>
</dd>
<dt><em>time_zero</em> (since Linux 3.12)</dt>
<dd><p>If <em>cap_usr_time_zero</em> is set, then the hardware clock (the TSC timestamp counter on x86) can be calculated from the <em>time_zero</em>, <em>time_mult</em>, and <em>time_shift</em> values:</p>
<pre><code>time = timestamp - time_zero;
quot = time / time_mult;
rem  = time % time_mult;
cyc  = (quot &lt;&lt; time_shift) + (rem &lt;&lt; time_shift) / time_mult;</code></pre>
<p>And vice versa:</p>
<pre><code>quot = cyc &gt;&gt; time_shift;
rem  = cyc &amp; (((u64)1 &lt;&lt; time_shift) - 1);
timestamp = time_zero + quot * time_mult +
            ((rem * time_mult) &gt;&gt; time_shift);</code></pre>
</dd>
<dt><em>data_head</em></dt>
<dd><p>This points to the head of the data section. The value continuously increases, it does not wrap. The value needs to be manually wrapped by the size of the mmap buffer before accessing the samples.</p>
<p>On SMP-capable platforms, after reading the <em>data_head</em> value, user space should issue an rmb().</p>
</dd>
<dt><em>data_tail</em></dt>
<dd><p>When the mapping is <strong>PROT_WRITE</strong>, the <em>data_tail</em> value should be written by user space to reflect the last read data. In this case, the kernel will not overwrite unread data.</p>
</dd>
<dt><em>data_offset</em> (since Linux 4.1)</dt>
<dd><p>Contains the offset of the location in the mmap buffer where perf sample data begins.</p>
</dd>
<dt><em>data_size</em> (since Linux 4.1)</dt>
<dd><p>Contains the size of the perf sample region within the mmap buffer.</p>
</dd>
<dt><em>aux_head</em>, <em>aux_tail</em>, <em>aux_offset</em>, <em>aux_size</em> (since Linux 4.1)</dt>
<dd><p>The AUX region allows <strong>mmap</strong>(2)-ing a separate sample buffer for high-bandwidth data streams (separate from the main perf sample buffer). An example of a high-bandwidth stream is instruction tracing support, as is found in newer Intel processors.</p>
<p>To set up an AUX area, first <em>aux_offset</em> needs to be set with an offset greater than <em>data_offset</em>+<em>data_size</em> and <em>aux_size</em> needs to be set to the desired buffer size. The desired offset and size must be page aligned, and the size must be a power of two. These values are then passed to mmap in order to map the AUX buffer. Pages in the AUX buffer are included as part of the <strong>RLIMIT_MEMLOCK</strong> resource limit (see <strong>setrlimit</strong>(2)), and also as part of the <em>perf_event_mlock_kb</em> allowance.</p>
<p>By default, the AUX buffer will be truncated if it will not fit in the available space in the ring buffer. If the AUX buffer is mapped as a read only buffer, then it will operate in ring buffer mode where old data will be overwritten by new. In overwrite mode, it might not be possible to infer where the new data began, and it is the consumer's job to disable measurement while reading to avoid possible data races.</p>
<p>The <em>aux_head</em> and <em>aux_tail</em> ring buffer pointers have the same behavior and ordering rules as the previous described <em>data_head</em> and <em>data_tail</em>.</p>
</dd>
</dl>
<p>The following 2^n ring-buffer pages have the layout described below.</p>
<p>If <em>perf_event_attr.sample_id_all</em> is set, then all event types will have the sample_type selected fields related to where/when (identity) an event took place (TID, TIME, ID, CPU, STREAM_ID) described in <strong>PERF_RECORD_SAMPLE</strong> below, it will be stashed just after the <em>perf_event_header</em> and the fields already present for the existing fields, that is, at the end of the payload. This allows a newer perf.data file to be supported by older perf tools, with the new optional fields being ignored.</p>
<p>The mmap values start with a header:</p>
<pre><code>struct perf_event_header {
    __u32   type;
    __u16   misc;
    __u16   size;
};</code></pre>
<p>Below, we describe the <em>perf_event_header</em> fields in more detail. For ease of reading, the fields with shorter descriptions are presented first.</p>
<dl>
<dt><em>size</em></dt>
<dd><p>This indicates the size of the record.</p>
</dd>
<dt><em>misc</em></dt>
<dd><p>The <em>misc</em> field contains additional information about the sample.</p>
<p>The CPU mode can be determined from this value by masking with <strong>PERF_RECORD_MISC_CPUMODE_MASK</strong> and looking for one of the following (note these are not bit masks, only one can be set at a time):</p>
<dl>
<dt><strong>PERF_RECORD_MISC_CPUMODE_UNKNOWN</strong></dt>
<dd><p>Unknown CPU mode.</p>
</dd>
<dt><strong>PERF_RECORD_MISC_KERNEL</strong></dt>
<dd><p>Sample happened in the kernel.</p>
</dd>
<dt><strong>PERF_RECORD_MISC_USER</strong></dt>
<dd><p>Sample happened in user code.</p>
</dd>
<dt><strong>PERF_RECORD_MISC_HYPERVISOR</strong></dt>
<dd><p>Sample happened in the hypervisor.</p>
</dd>
<dt><strong>PERF_RECORD_MISC_GUEST_KERNEL</strong> (since Linux 2.6.35)</dt>
<dd><p>Sample happened in the guest kernel.</p>
</dd>
<dt><strong>PERF_RECORD_MISC_GUEST_USER (since Linux 2.6.35)</strong></dt>
<dd><p>Sample happened in guest user code.</p>
</dd>
</dl>
</dd>
</dl>
<blockquote>
<p>Since the following three statuses are generated by different record types, they alias to the same bit:</p>
<dl>
<dt><strong>PERF_RECORD_MISC_MMAP_DATA</strong> (since Linux 3.10)</dt>
<dd><p>This is set when the mapping is not executable; otherwise the mapping is executable.</p>
</dd>
<dt><strong>PERF_RECORD_MISC_COMM_EXEC</strong> (since Linux 3.16)</dt>
<dd><p>This is set for a <strong>PERF_RECORD_COMM</strong> record on kernels more recent than Linux 3.16 if a process name change was caused by an <strong>exec</strong>(2) system call.</p>
</dd>
<dt><strong>PERF_RECORD_MISC_SWITCH_OUT</strong> (since Linux 4.3)</dt>
<dd><p>When a <strong>PERF_RECORD_SWITCH</strong> or <strong>PERF_RECORD_SWITCH_CPU_WIDE</strong> record is generated, this bit indicates that the context switch is away from the current process (instead of into the current process).</p>
</dd>
</dl>
</blockquote>
<blockquote>
<p>In addition, the following bits can be set:</p>
<dl>
<dt><strong>PERF_RECORD_MISC_EXACT_IP</strong></dt>
<dd><p>This indicates that the content of <strong>PERF_SAMPLE_IP</strong> points to the actual instruction that triggered the event. See also <em>perf_event_attr.precise_ip</em>.</p>
</dd>
<dt><strong>PERF_RECORD_MISC_EXT_RESERVED</strong> (since Linux 2.6.35)</dt>
<dd><p>This indicates there is extended data available (currently not used).</p>
</dd>
<dt><strong>PERF_RECORD_MISC_PROC_MAP_PARSE_TIMEOUT</strong></dt>
<dd><p>This bit is not set by the kernel. It is reserved for the user-space perf utility to indicate that <em>/proc/i[pid]/maps</em> parsing was taking too long and was stopped, and thus the mmap records may be truncated.</p>
</dd>
</dl>
</blockquote>
<dl>
<dt><em>type</em></dt>
<dd><p>The <em>type</em> value is one of the below. The values in the corresponding record (that follows the header) depend on the <em>type</em> selected as shown.</p>
<dl>
<dt><strong>PERF_RECORD_MMAP</strong></dt>
<dd><p>The MMAP events record the <strong>PROT_EXEC</strong> mappings so that we can correlate user-space IPs to code. They have the following structure:</p>
<pre><code>struct {
    struct perf_event_header header;
    u32    pid, tid;
    u64    addr;
    u64    len;
    u64    pgoff;
    char   filename[];
};</code></pre>
<dl>
<dt><em>pid</em></dt>
<dd><p>is the process ID.</p>
</dd>
<dt><em>tid</em></dt>
<dd><p>is the thread ID.</p>
</dd>
<dt><em>addr</em></dt>
<dd><p>is the address of the allocated memory. <em>len</em> is the length of the allocated memory. <em>pgoff</em> is the page offset of the allocated memory. <em>filename</em> is a string describing the backing of the allocated memory.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_LOST</strong></dt>
<dd><p>This record indicates when events are lost.</p>
<pre><code>struct {
    struct perf_event_header header;
    u64    id;
    u64    lost;
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>id</em></dt>
<dd><p>is the unique event ID for the samples that were lost.</p>
</dd>
<dt><em>lost</em></dt>
<dd><p>is the number of events that were lost.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_COMM</strong></dt>
<dd><p>This record indicates a change in the process name.</p>
<pre><code>struct {
    struct perf_event_header header;
    u32    pid;
    u32    tid;
    char   comm[];
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>pid</em></dt>
<dd><p>is the process ID.</p>
</dd>
<dt><em>tid</em></dt>
<dd><p>is the thread ID.</p>
</dd>
<dt><em>comm</em></dt>
<dd><p>is a string containing the new name of the process.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_EXIT</strong></dt>
<dd><p>This record indicates a process exit event.</p>
<pre><code>struct {
    struct perf_event_header header;
    u32    pid, ppid;
    u32    tid, ptid;
    u64    time;
    struct sample_id sample_id;
};</code></pre>
</dd>
<dt><strong>PERF_RECORD_THROTTLE</strong>, <strong>PERF_RECORD_UNTHROTTLE</strong></dt>
<dd><p>This record indicates a throttle/unthrottle event.</p>
<pre><code>struct {
    struct perf_event_header header;
    u64    time;
    u64    id;
    u64    stream_id;
    struct sample_id sample_id;
};</code></pre>
</dd>
<dt><strong>PERF_RECORD_FORK</strong></dt>
<dd><p>This record indicates a fork event.</p>
<pre><code>struct {
    struct perf_event_header header;
    u32    pid, ppid;
    u32    tid, ptid;
    u64    time;
    struct sample_id sample_id;
};</code></pre>
</dd>
<dt><strong>PERF_RECORD_READ</strong></dt>
<dd><p>This record indicates a read event.</p>
<pre><code>struct {
    struct perf_event_header header;
    u32    pid, tid;
    struct read_format values;
    struct sample_id sample_id;
};</code></pre>
</dd>
<dt><strong>PERF_RECORD_SAMPLE</strong></dt>
<dd><p>This record indicates a sample.</p>
<pre><code>struct {
    struct perf_event_header header;
    u64    sample_id;   /* if PERF_SAMPLE_IDENTIFIER */
    u64    ip;          /* if PERF_SAMPLE_IP */
    u32    pid, tid;    /* if PERF_SAMPLE_TID */
    u64    time;        /* if PERF_SAMPLE_TIME */
    u64    addr;        /* if PERF_SAMPLE_ADDR */
    u64    id;          /* if PERF_SAMPLE_ID */
    u64    stream_id;   /* if PERF_SAMPLE_STREAM_ID */
    u32    cpu, res;    /* if PERF_SAMPLE_CPU */
    u64    period;      /* if PERF_SAMPLE_PERIOD */
    struct read_format v;
                        /* if PERF_SAMPLE_READ */
    u64    nr;          /* if PERF_SAMPLE_CALLCHAIN */
    u64    ips[nr];     /* if PERF_SAMPLE_CALLCHAIN */
    u32    size;        /* if PERF_SAMPLE_RAW */
    char   data[size];  /* if PERF_SAMPLE_RAW */
    u64    bnr;         /* if PERF_SAMPLE_BRANCH_STACK */
    struct perf_branch_entry lbr[bnr];
                        /* if PERF_SAMPLE_BRANCH_STACK */
    u64    abi;         /* if PERF_SAMPLE_REGS_USER */
    u64    regs[weight(mask)];
                        /* if PERF_SAMPLE_REGS_USER */
    u64    size;        /* if PERF_SAMPLE_STACK_USER */
    char   data[size];  /* if PERF_SAMPLE_STACK_USER */
    u64    dyn_size;    /* if PERF_SAMPLE_STACK_USER &amp;&amp;
                           size != 0 */
    u64    weight;      /* if PERF_SAMPLE_WEIGHT */
    u64    data_src;    /* if PERF_SAMPLE_DATA_SRC */
    u64    transaction; /* if PERF_SAMPLE_TRANSACTION */
    u64    abi;         /* if PERF_SAMPLE_REGS_INTR */
    u64    regs[weight(mask)];
                        /* if PERF_SAMPLE_REGS_INTR */
    u64    phys_addr;   /* if PERF_SAMPLE_PHYS_ADDR */
    u64    cgroup;      /* if PERF_SAMPLE_CGROUP */
};</code></pre>
<dl>
<dt><em>sample_id</em></dt>
<dd><p>If <strong>PERF_SAMPLE_IDENTIFIER</strong> is enabled, a 64-bit unique ID is included. This is a duplication of the <strong>PERF_SAMPLE_ID</strong> <em>id</em> value, but included at the beginning of the sample so parsers can easily obtain the value.</p>
</dd>
<dt><em>ip</em></dt>
<dd><p>If <strong>PERF_SAMPLE_IP</strong> is enabled, then a 64-bit instruction pointer value is included.</p>
</dd>
<dt><em>pid</em>, <em>tid</em></dt>
<dd><p>If <strong>PERF_SAMPLE_TID</strong> is enabled, then a 32-bit process ID and 32-bit thread ID are included.</p>
</dd>
<dt><em>time</em></dt>
<dd><p>If <strong>PERF_SAMPLE_TIME</strong> is enabled, then a 64-bit timestamp is included. This is obtained via local_clock() which is a hardware timestamp if available and the jiffies value if not.</p>
</dd>
<dt><em>addr</em></dt>
<dd><p>If <strong>PERF_SAMPLE_ADDR</strong> is enabled, then a 64-bit address is included. This is usually the address of a tracepoint, breakpoint, or software event; otherwise the value is 0.</p>
</dd>
<dt><em>id</em></dt>
<dd><p>If <strong>PERF_SAMPLE_ID</strong> is enabled, a 64-bit unique ID is included. If the event is a member of an event group, the group leader ID is returned. This ID is the same as the one returned by <strong>PERF_FORMAT_ID</strong>.</p>
</dd>
<dt><em>stream_id</em></dt>
<dd><p>If <strong>PERF_SAMPLE_STREAM_ID</strong> is enabled, a 64-bit unique ID is included. Unlike <strong>PERF_SAMPLE_ID</strong> the actual ID is returned, not the group leader. This ID is the same as the one returned by <strong>PERF_FORMAT_ID</strong>.</p>
</dd>
<dt><em>cpu</em>, <em>res</em></dt>
<dd><p>If <strong>PERF_SAMPLE_CPU</strong> is enabled, this is a 32-bit value indicating which CPU was being used, in addition to a reserved (unused) 32-bit value.</p>
</dd>
<dt><em>period</em></dt>
<dd><p>If <strong>PERF_SAMPLE_PERIOD</strong> is enabled, a 64-bit value indicating the current sampling period is written.</p>
</dd>
<dt><em>v</em></dt>
<dd><p>If <strong>PERF_SAMPLE_READ</strong> is enabled, a structure of type read_format is included which has values for all events in the event group. The values included depend on the <em>read_format</em> value used at <strong>perf_event_open</strong>() time.</p>
</dd>
<dt><em>nr</em>, <em>ips[nr]</em></dt>
<dd><p>If <strong>PERF_SAMPLE_CALLCHAIN</strong> is enabled, then a 64-bit number is included which indicates how many following 64-bit instruction pointers will follow. This is the current callchain.</p>
</dd>
<dt><em>size</em>, <em>data[size]</em></dt>
<dd><p>If <strong>PERF_SAMPLE_RAW</strong> is enabled, then a 32-bit value indicating size is included followed by an array of 8-bit values of length size. The values are padded with 0 to have 64-bit alignment.</p>
<p>This RAW record data is opaque with respect to the ABI. The ABI doesn't make any promises with respect to the stability of its content, it may vary depending on event, hardware, and kernel version.</p>
</dd>
<dt><em>bnr</em>, <em>lbr[bnr]</em></dt>
<dd><p>If <strong>PERF_SAMPLE_BRANCH_STACK</strong> is enabled, then a 64-bit value indicating the number of records is included, followed by <em>bnr</em> <em>perf_branch_entry</em> structures which each include the fields:</p>
<dl>
<dt><em>from</em></dt>
<dd><p>This indicates the source instruction (may not be a branch).</p>
</dd>
<dt><em>to</em></dt>
<dd><p>The branch target.</p>
</dd>
<dt><em>mispred</em></dt>
<dd><p>The branch target was mispredicted.</p>
</dd>
<dt><em>predicted</em></dt>
<dd><p>The branch target was predicted.</p>
</dd>
<dt><em>in_tx</em> (since Linux 3.11)</dt>
<dd><p>The branch was in a transactional memory transaction.</p>
</dd>
<dt><em>abort</em> (since Linux 3.11)</dt>
<dd><p>The branch was in an aborted transactional memory transaction.</p>
</dd>
<dt><em>cycles</em> (since Linux 4.3)</dt>
<dd><p>This reports the number of cycles elapsed since the previous branch stack update.</p>
</dd>
</dl>
<p>The entries are from most to least recent, so the first entry has the most recent branch.</p>
<p>Support for <em>mispred</em>, <em>predicted</em>, and <em>cycles</em> is optional; if not supported, those values will be 0.</p>
<p>The type of branches recorded is specified by the <em>branch_sample_type</em> field.</p>
</dd>
<dt><em>abi</em>, <em>regs[weight(mask)]</em></dt>
<dd><p>If <strong>PERF_SAMPLE_REGS_USER</strong> is enabled, then the user CPU registers are recorded.</p>
<p>The <em>abi</em> field is one of <strong>PERF_SAMPLE_REGS_ABI_NONE</strong>, <strong>PERF_SAMPLE_REGS_ABI_32</strong>, or <strong>PERF_SAMPLE_REGS_ABI_64</strong>.</p>
<p>The <em>regs</em> field is an array of the CPU registers that were specified by the <em>sample_regs_user</em> attr field. The number of values is the number of bits set in the <em>sample_regs_user</em> bit mask.</p>
</dd>
<dt><em>size</em>, <em>data[size]</em>, <em>dyn_size</em></dt>
<dd><p>If <strong>PERF_SAMPLE_STACK_USER</strong> is enabled, then the user stack is recorded. This can be used to generate stack backtraces. <em>size</em> is the size requested by the user in <em>sample_stack_user</em> or else the maximum record size. <em>data</em> is the stack data (a raw dump of the memory pointed to by the stack pointer at the time of sampling). <em>dyn_size</em> is the amount of data actually dumped (can be less than <em>size</em>). Note that <em>dyn_size</em> is omitted if <em>size</em> is 0.</p>
</dd>
<dt><em>weight</em></dt>
<dd><p>If <strong>PERF_SAMPLE_WEIGHT</strong> is enabled, then a 64-bit value provided by the hardware is recorded that indicates how costly the event was. This allows expensive events to stand out more clearly in profiles.</p>
</dd>
<dt><em>data_src</em></dt>
<dd><p>If <strong>PERF_SAMPLE_DATA_SRC</strong> is enabled, then a 64-bit value is recorded that is made up of the following fields:</p>
<dl>
<dt><em>mem_op</em></dt>
<dd><p>Type of opcode, a bitwise combination of:</p>
</dd>
</dl>
<blockquote>
<dl>
<dt><strong>PERF_MEM_OP_NA</strong></dt>
<dd><p>Not available</p>
</dd>
<dt><strong>PERF_MEM_OP_LOAD</strong></dt>
<dd><p>Load instruction</p>
</dd>
<dt><strong>PERF_MEM_OP_STORE</strong></dt>
<dd><p>Store instruction</p>
</dd>
<dt><strong>PERF_MEM_OP_PFETCH</strong></dt>
<dd><p>Prefetch</p>
</dd>
<dt><strong>PERF_MEM_OP_EXEC</strong></dt>
<dd><p>Executable code</p>
</dd>
</dl>
</blockquote>
<dl>
<dt><em>mem_lvl</em></dt>
<dd><p>Memory hierarchy level hit or miss, a bitwise combination of the following, shifted left by <strong>PERF_MEM_LVL_SHIFT</strong>:</p>
</dd>
</dl>
<blockquote>
<dl>
<dt><strong>PERF_MEM_LVL_NA</strong></dt>
<dd><p>Not available</p>
</dd>
<dt><strong>PERF_MEM_LVL_HIT</strong></dt>
<dd><p>Hit</p>
</dd>
<dt><strong>PERF_MEM_LVL_MISS</strong></dt>
<dd><p>Miss</p>
</dd>
<dt><strong>PERF_MEM_LVL_L1</strong></dt>
<dd><p>Level 1 cache</p>
</dd>
<dt><strong>PERF_MEM_LVL_LFB</strong></dt>
<dd><p>Line fill buffer</p>
</dd>
<dt><strong>PERF_MEM_LVL_L2</strong></dt>
<dd><p>Level 2 cache</p>
</dd>
<dt><strong>PERF_MEM_LVL_L3</strong></dt>
<dd><p>Level 3 cache</p>
</dd>
<dt><strong>PERF_MEM_LVL_LOC_RAM</strong></dt>
<dd><p>Local DRAM</p>
</dd>
<dt><strong>PERF_MEM_LVL_REM_RAM1</strong></dt>
<dd><p>Remote DRAM 1 hop</p>
</dd>
<dt><strong>PERF_MEM_LVL_REM_RAM2</strong></dt>
<dd><p>Remote DRAM 2 hops</p>
</dd>
<dt><strong>PERF_MEM_LVL_REM_CCE1</strong></dt>
<dd><p>Remote cache 1 hop</p>
</dd>
<dt><strong>PERF_MEM_LVL_REM_CCE2</strong></dt>
<dd><p>Remote cache 2 hops</p>
</dd>
<dt><strong>PERF_MEM_LVL_IO</strong></dt>
<dd><p>I/O memory</p>
</dd>
<dt><strong>PERF_MEM_LVL_UNC</strong></dt>
<dd><p>Uncached memory</p>
</dd>
</dl>
</blockquote>
<dl>
<dt><em>mem_snoop</em></dt>
<dd><p>Snoop mode, a bitwise combination of the following, shifted left by <strong>PERF_MEM_SNOOP_SHIFT</strong>:</p>
</dd>
</dl>
<blockquote>
<dl>
<dt><strong>PERF_MEM_SNOOP_NA</strong></dt>
<dd><p>Not available</p>
</dd>
<dt><strong>PERF_MEM_SNOOP_NONE</strong></dt>
<dd><p>No snoop</p>
</dd>
<dt><strong>PERF_MEM_SNOOP_HIT</strong></dt>
<dd><p>Snoop hit</p>
</dd>
<dt><strong>PERF_MEM_SNOOP_MISS</strong></dt>
<dd><p>Snoop miss</p>
</dd>
<dt><strong>PERF_MEM_SNOOP_HITM</strong></dt>
<dd><p>Snoop hit modified</p>
</dd>
</dl>
</blockquote>
<dl>
<dt><em>mem_lock</em></dt>
<dd><p>Lock instruction, a bitwise combination of the following, shifted left by <strong>PERF_MEM_LOCK_SHIFT</strong>:</p>
</dd>
</dl>
<blockquote>
<dl>
<dt><strong>PERF_MEM_LOCK_NA</strong></dt>
<dd><p>Not available</p>
</dd>
<dt><strong>PERF_MEM_LOCK_LOCKED</strong></dt>
<dd><p>Locked transaction</p>
</dd>
</dl>
</blockquote>
<dl>
<dt><em>mem_dtlb</em></dt>
<dd><p>TLB access hit or miss, a bitwise combination of the following, shifted left by <strong>PERF_MEM_TLB_SHIFT</strong>:</p>
</dd>
</dl>
<blockquote>
<dl>
<dt><strong>PERF_MEM_TLB_NA</strong></dt>
<dd><p>Not available</p>
</dd>
<dt><strong>PERF_MEM_TLB_HIT</strong></dt>
<dd><p>Hit</p>
</dd>
<dt><strong>PERF_MEM_TLB_MISS</strong></dt>
<dd><p>Miss</p>
</dd>
<dt><strong>PERF_MEM_TLB_L1</strong></dt>
<dd><p>Level 1 TLB</p>
</dd>
<dt><strong>PERF_MEM_TLB_L2</strong></dt>
<dd><p>Level 2 TLB</p>
</dd>
<dt><strong>PERF_MEM_TLB_WK</strong></dt>
<dd><p>Hardware walker</p>
</dd>
<dt><strong>PERF_MEM_TLB_OS</strong></dt>
<dd><p>OS fault handler</p>
</dd>
</dl>
</blockquote>
</dd>
<dt><em>transaction</em></dt>
<dd><p>If the <strong>PERF_SAMPLE_TRANSACTION</strong> flag is set, then a 64-bit field is recorded describing the sources of any transactional memory aborts.</p>
<p>The field is a bitwise combination of the following values:</p>
<dl>
<dt><strong>PERF_TXN_ELISION</strong></dt>
<dd><p>Abort from an elision type transaction (Intel-CPU-specific).</p>
</dd>
<dt><strong>PERF_TXN_TRANSACTION</strong></dt>
<dd><p>Abort from a generic transaction.</p>
</dd>
<dt><strong>PERF_TXN_SYNC</strong></dt>
<dd><p>Synchronous abort (related to the reported instruction).</p>
</dd>
<dt><strong>PERF_TXN_ASYNC</strong></dt>
<dd><p>Asynchronous abort (not related to the reported instruction).</p>
</dd>
<dt><strong>PERF_TXN_RETRY</strong></dt>
<dd><p>Retryable abort (retrying the transaction may have succeeded).</p>
</dd>
<dt><strong>PERF_TXN_CONFLICT</strong></dt>
<dd><p>Abort due to memory conflicts with other threads.</p>
</dd>
<dt><strong>PERF_TXN_CAPACITY_WRITE</strong></dt>
<dd><p>Abort due to write capacity overflow.</p>
</dd>
<dt><strong>PERF_TXN_CAPACITY_READ</strong></dt>
<dd><p>Abort due to read capacity overflow.</p>
</dd>
</dl>
<p>In addition, a user-specified abort code can be obtained from the high 32 bits of the field by shifting right by <strong>PERF_TXN_ABORT_SHIFT</strong> and masking with the value <strong>PERF_TXN_ABORT_MASK</strong>.</p>
</dd>
<dt><em>abi</em>, <em>regs[weight(mask)]</em></dt>
<dd><p>If <strong>PERF_SAMPLE_REGS_INTR</strong> is enabled, then the user CPU registers are recorded.</p>
<p>The <em>abi</em> field is one of <strong>PERF_SAMPLE_REGS_ABI_NONE</strong>, <strong>PERF_SAMPLE_REGS_ABI_32</strong>, or <strong>PERF_SAMPLE_REGS_ABI_64</strong>.</p>
<p>The <em>regs</em> field is an array of the CPU registers that were specified by the <em>sample_regs_intr</em> attr field. The number of values is the number of bits set in the <em>sample_regs_intr</em> bit mask.</p>
</dd>
<dt><em>phys_addr</em></dt>
<dd><p>If the <strong>PERF_SAMPLE_PHYS_ADDR</strong> flag is set, then the 64-bit physical address is recorded.</p>
</dd>
<dt><em>cgroup</em></dt>
<dd><p>If the <strong>PERF_SAMPLE_CGROUP</strong> flag is set, then the 64-bit cgroup ID (for the perf_event subsystem) is recorded. To get the pathname of the cgroup, the ID should match to one in a <strong>PERF_RECORD_CGROUP .</strong></p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_MMAP2</strong></dt>
<dd><p>This record includes extended information on <strong>mmap</strong>(2) calls returning executable mappings. The format is similar to that of the <strong>PERF_RECORD_MMAP</strong> record, but includes extra values that allow uniquely identifying shared mappings.</p>
<pre><code>struct {
    struct perf_event_header header;
    u32    pid;
    u32    tid;
    u64    addr;
    u64    len;
    u64    pgoff;
    u32    maj;
    u32    min;
    u64    ino;
    u64    ino_generation;
    u32    prot;
    u32    flags;
    char   filename[];
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>pid</em></dt>
<dd><p>is the process ID.</p>
</dd>
<dt><em>tid</em></dt>
<dd><p>is the thread ID.</p>
</dd>
<dt><em>addr</em></dt>
<dd><p>is the address of the allocated memory.</p>
</dd>
<dt><em>len</em></dt>
<dd><p>is the length of the allocated memory.</p>
</dd>
<dt><em>pgoff</em></dt>
<dd><p>is the page offset of the allocated memory.</p>
</dd>
<dt><em>maj</em></dt>
<dd><p>is the major ID of the underlying device.</p>
</dd>
<dt><em>min</em></dt>
<dd><p>is the minor ID of the underlying device.</p>
</dd>
<dt><em>ino</em></dt>
<dd><p>is the inode number.</p>
</dd>
<dt><em>ino_generation</em></dt>
<dd><p>is the inode generation.</p>
</dd>
<dt><em>prot</em></dt>
<dd><p>is the protection information.</p>
</dd>
<dt><em>flags</em></dt>
<dd><p>is the flags information.</p>
</dd>
<dt><em>filename</em></dt>
<dd><p>is a string describing the backing of the allocated memory.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_AUX</strong> (since Linux 4.1)</dt>
<dd><p>This record reports that new data is available in the separate AUX buffer region.</p>
<pre><code>struct {
    struct perf_event_header header;
    u64    aux_offset;
    u64    aux_size;
    u64    flags;
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>aux_offset</em></dt>
<dd><p>offset in the AUX mmap region where the new data begins.</p>
</dd>
<dt><em>aux_size</em></dt>
<dd><p>size of the data made available.</p>
</dd>
<dt><em>flags</em></dt>
<dd><p>describes the AUX update.</p>
<dl>
<dt><strong>PERF_AUX_FLAG_TRUNCATED</strong></dt>
<dd><p>if set, then the data returned was truncated to fit the available buffer size.</p>
</dd>
<dt><strong>PERF_AUX_FLAG_OVERWRITE</strong></dt>
<dd><p>if set, then the data returned has overwritten previous data.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_ITRACE_START</strong> (since Linux 4.1)</dt>
<dd><p>This record indicates which process has initiated an instruction trace event, allowing tools to properly correlate the instruction addresses in the AUX buffer with the proper executable.</p>
<pre><code>struct {
    struct perf_event_header header;
    u32    pid;
    u32    tid;
};</code></pre>
<dl>
<dt><em>pid</em></dt>
<dd><p>process ID of the thread starting an instruction trace.</p>
</dd>
<dt><em>tid</em></dt>
<dd><p>thread ID of the thread starting an instruction trace.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_LOST_SAMPLES</strong> (since Linux 4.2)</dt>
<dd><p>When using hardware sampling (such as Intel PEBS) this record indicates some number of samples that may have been lost.</p>
<pre><code>struct {
    struct perf_event_header header;
    u64    lost;
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>lost</em></dt>
<dd><p>the number of potentially lost samples.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_SWITCH</strong> (since Linux 4.3)</dt>
<dd><p>This record indicates a context switch has happened. The <strong>PERF_RECORD_MISC_SWITCH_OUT</strong> bit in the <em>misc</em> field indicates whether it was a context switch into or away from the current process.</p>
<pre><code>struct {
    struct perf_event_header header;
    struct sample_id sample_id;
};</code></pre>
</dd>
<dt><strong>PERF_RECORD_SWITCH_CPU_WIDE</strong> (since Linux 4.3)</dt>
<dd><p>As with <strong>PERF_RECORD_SWITCH</strong> this record indicates a context switch has happened, but it only occurs when sampling in CPU-wide mode and provides additional information on the process being switched to/from. The <strong>PERF_RECORD_MISC_SWITCH_OUT</strong> bit in the <em>misc</em> field indicates whether it was a context switch into or away from the current process.</p>
<pre><code>struct {
    struct perf_event_header header;
    u32 next_prev_pid;
    u32 next_prev_tid;
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>next_prev_pid</em></dt>
<dd><p>The process ID of the previous (if switching in) or next (if switching out) process on the CPU.</p>
</dd>
<dt><em>next_prev_tid</em></dt>
<dd><p>The thread ID of the previous (if switching in) or next (if switching out) thread on the CPU.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_NAMESPACES</strong> (since Linux 4.11)</dt>
<dd><p>This record includes various namespace information of a process.</p>
<pre><code>struct {
    struct perf_event_header header;
    u32    pid;
    u32    tid;
    u64    nr_namespaces;
    struct { u64 dev, inode } [nr_namespaces];
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>pid</em></dt>
<dd><p>is the process ID</p>
</dd>
<dt><em>tid</em></dt>
<dd><p>is the thread ID</p>
</dd>
<dt><em>nr_namespace</em></dt>
<dd><p>is the number of namespaces in this record</p>
</dd>
</dl>
<p>Each namespace has <em>dev</em> and <em>inode</em> fields and is recorded in the fixed position like below:</p>
<dl>
<dt><strong>NET_NS_INDEX</strong>=<strong>0</strong></dt>
<dd><p>Network namespace</p>
</dd>
<dt><strong>UTS_NS_INDEX</strong>=<strong>1</strong></dt>
<dd><p>UTS namespace</p>
</dd>
<dt><strong>IPC_NS_INDEX</strong>=<strong>2</strong></dt>
<dd><p>IPC namespace</p>
</dd>
<dt><strong>PID_NS_INDEX</strong>=<strong>3</strong></dt>
<dd><p>PID namespace</p>
</dd>
<dt><strong>USER_NS_INDEX</strong>=<strong>4</strong></dt>
<dd><p>User namespace</p>
</dd>
<dt><strong>MNT_NS_INDEX</strong>=<strong>5</strong></dt>
<dd><p>Mount namespace</p>
</dd>
<dt><strong>CGROUP_NS_INDEX</strong>=<strong>6</strong></dt>
<dd><p>Cgroup namespace</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_KSYMBOL</strong> (since Linux 5.0)</dt>
<dd><p>This record indicates kernel symbol register/unregister events.</p>
<pre><code>struct {
    struct perf_event_header header;
    u64    addr;
    u32    len;
    u16    ksym_type;
    u16    flags;
    char   name[];
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>addr</em></dt>
<dd><p>is the address of the kernel symbol.</p>
</dd>
<dt><em>len</em></dt>
<dd><p>is the length of the kernel symbol.</p>
</dd>
<dt><em>ksym_type</em></dt>
<dd><p>is the type of the kernel symbol. Currently the following types are available:</p>
<dl>
<dt><strong>PERF_RECORD_KSYMBOL_TYPE_BPF</strong></dt>
<dd><p>The kernel symbol is a BPF function.</p>
</dd>
</dl>
</dd>
<dt><em>flags</em></dt>
<dd><p>If the <strong>PERF_RECORD_KSYMBOL_FLAGS_UNREGISTER</strong> is set, then this event is for unregistering the kernel symbol.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_BPF_EVENT</strong> (since Linux 5.0)</dt>
<dd><p>This record indicates BPF program is loaded or unloaded.</p>
<pre><code>struct {
    struct perf_event_header header;
    u16 type;
    u16 flags;
    u32 id;
    u8 tag[BPF_TAG_SIZE];
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>type</em></dt>
<dd><p>is one of the following values:</p>
<dl>
<dt><strong>PERF_BPF_EVENT_PROG_LOAD</strong></dt>
<dd><p>A BPF program is loaded</p>
</dd>
<dt><strong>PERF_BPF_EVENT_PROG_UNLOAD</strong></dt>
<dd><p>A BPF program is unloaded</p>
</dd>
</dl>
</dd>
<dt><em>id</em></dt>
<dd><p>is the ID of the BPF program.</p>
</dd>
<dt><em>tag</em></dt>
<dd><p>is the tag of the BPF program. Currently, <strong>BPF_TAG_SIZE</strong> is defined as 8.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_CGROUP</strong> (since Linux 5.7)</dt>
<dd><p>This record indicates a new cgroup is created and activated.</p>
<pre><code>struct {
    struct perf_event_header header;
    u64    id;
    char   path[];
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>id</em></dt>
<dd><p>is the cgroup identifier. This can be also retrieved by <strong>name_to_handle_at</strong>(2) on the cgroup path (as a file handle).</p>
</dd>
<dt><em>path</em></dt>
<dd><p>is the path of the cgroup from the root.</p>
</dd>
</dl>
</dd>
<dt><strong>PERF_RECORD_TEXT_POKE</strong> (since Linux 5.8)</dt>
<dd><p>This record indicates a change in the kernel text. This includes addition and removal of the text and the corresponding length is zero in this case.</p>
<pre><code>struct {
    struct perf_event_header header;
    u64    addr;
    u16    old_len;
    u16    new_len;
    u8     bytes[];
    struct sample_id sample_id;
};</code></pre>
<dl>
<dt><em>addr</em></dt>
<dd><p>is the address of the change</p>
</dd>
<dt><em>old_len</em></dt>
<dd><p>is the old length</p>
</dd>
<dt><em>new_len</em></dt>
<dd><p>is the new length</p>
</dd>
<dt><em>bytes</em></dt>
<dd><p>contains old bytes immediately followed by new bytes.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
<h2>Overflow handling</h2>
<p>Events can be set to notify when a threshold is crossed, indicating an overflow. Overflow conditions can be captured by monitoring the event file descriptor with <strong>poll</strong>(2), <strong>select</strong>(2), or <strong>epoll</strong>(7). Alternatively, the overflow events can be captured via sa signal handler, by enabling I/O signaling on the file descriptor; see the discussion of the <strong>F_SETOWN</strong> and <strong>F_SETSIG</strong> operations in <strong>fcntl</strong>(2).</p>
<p>Overflows are generated only by sampling events (<em>sample_period</em> must have a nonzero value).</p>
<p>There are two ways to generate overflow notifications.</p>
<p>The first is to set a <em>wakeup_events</em> or <em>wakeup_watermark</em> value that will trigger if a certain number of samples or bytes have been written to the mmap ring buffer. In this case, <strong>POLL_IN</strong> is indicated.</p>
<p>The other way is by use of the <strong>PERF_EVENT_IOC_REFRESH</strong> ioctl. This ioctl adds to a counter that decrements each time the event overflows. When nonzero, <strong>POLL_IN</strong> is indicated, but once the counter reaches 0 <strong>POLL_HUP</strong> is indicated and the underlying event is disabled.</p>
<p>Refreshing an event group leader refreshes all siblings and refreshing with a parameter of 0 currently enables infinite refreshes; these behaviors are unsupported and should not be relied on.</p>
<p>Starting with Linux 3.18, <strong>POLL_HUP</strong> is indicated if the event being monitored is attached to a different process and that process exits.</p>
<h2>rdpmc instruction</h2>
<p>Starting with Linux 3.4 on x86, you can use the <em>rdpmc</em> instruction to get low-latency reads without having to enter the kernel. Note that using <em>rdpmc</em> is not necessarily faster than other methods for reading event values.</p>
<p>Support for this can be detected with the <em>cap_usr_rdpmc</em> field in the mmap page; documentation on how to calculate event values can be found in that section.</p>
<p>Originally, when rdpmc support was enabled, any process (not just ones with an active perf event) could use the rdpmc instruction to access the counters. Starting with Linux 4.0, rdpmc support is only allowed if an event is currently enabled in a process's context. To restore the old behavior, write the value 2 to <em>/sys/devices/cpu/rdpmc</em>.</p>
<h2>perf_event ioctl calls</h2>
<p>Various ioctls act on <strong>perf_event_open</strong>() file descriptors:</p>
<dl>
<dt><strong>PERF_EVENT_IOC_ENABLE</strong></dt>
<dd><p>This enables the individual event or event group specified by the file descriptor argument.</p>
<p>If the <strong>PERF_IOC_FLAG_GROUP</strong> bit is set in the ioctl argument, then all events in a group are enabled, even if the event specified is not the group leader (but see BUGS).</p>
</dd>
<dt><strong>PERF_EVENT_IOC_DISABLE</strong></dt>
<dd><p>This disables the individual counter or event group specified by the file descriptor argument.</p>
<p>Enabling or disabling the leader of a group enables or disables the entire group; that is, while the group leader is disabled, none of the counters in the group will count. Enabling or disabling a member of a group other than the leader affects only that counter; disabling a non-leader stops that counter from counting but doesn't affect any other counter.</p>
<p>If the <strong>PERF_IOC_FLAG_GROUP</strong> bit is set in the ioctl argument, then all events in a group are disabled, even if the event specified is not the group leader (but see BUGS).</p>
</dd>
<dt><strong>PERF_EVENT_IOC_REFRESH</strong></dt>
<dd><p>Non-inherited overflow counters can use this to enable a counter for a number of overflows specified by the argument, after which it is disabled. Subsequent calls of this ioctl add the argument value to the current count. An overflow notification with <strong>POLL_IN</strong> set will happen on each overflow until the count reaches 0; when that happens a notification with <strong>POLL_HUP</strong> set is sent and the event is disabled. Using an argument of 0 is considered undefined behavior.</p>
</dd>
<dt><strong>PERF_EVENT_IOC_RESET</strong></dt>
<dd><p>Reset the event count specified by the file descriptor argument to zero. This resets only the counts; there is no way to reset the multiplexing <em>time_enabled</em> or <em>time_running</em> values.</p>
<p>If the <strong>PERF_IOC_FLAG_GROUP</strong> bit is set in the ioctl argument, then all events in a group are reset, even if the event specified is not the group leader (but see BUGS).</p>
</dd>
<dt><strong>PERF_EVENT_IOC_PERIOD</strong></dt>
<dd><p>This updates the overflow period for the event.</p>
<p>Since Linux 3.7 (on ARM) and Linux 3.14 (all other architectures), the new period takes effect immediately. On older kernels, the new period did not take effect until after the next overflow.</p>
<p>The argument is a pointer to a 64-bit value containing the desired new period.</p>
<p>Prior to Linux 2.6.36, this ioctl always failed due to a bug in the kernel.</p>
</dd>
<dt><strong>PERF_EVENT_IOC_SET_OUTPUT</strong></dt>
<dd><p>This tells the kernel to report event notifications to the specified file descriptor rather than the default one. The file descriptors must all be on the same CPU.</p>
<p>The argument specifies the desired file descriptor, or -1 if output should be ignored.</p>
</dd>
<dt><strong>PERF_EVENT_IOC_SET_FILTER</strong> (since Linux 2.6.33)</dt>
<dd><p>This adds an ftrace filter to this event.</p>
<p>The argument is a pointer to the desired ftrace filter.</p>
</dd>
<dt><strong>PERF_EVENT_IOC_ID</strong> (since Linux 3.12)</dt>
<dd><p>This returns the event ID value for the given event file descriptor.</p>
<p>The argument is a pointer to a 64-bit unsigned integer to hold the result.</p>
</dd>
<dt><strong>PERF_EVENT_IOC_SET_BPF</strong> (since Linux 4.1)</dt>
<dd><p>This allows attaching a Berkeley Packet Filter (BPF) program to an existing kprobe tracepoint event. You need <strong>CAP_PERFMON</strong> (since Linux 5.8) or <strong>CAP_SYS_ADMIN</strong> privileges to use this ioctl.</p>
<p>The argument is a BPF program file descriptor that was created by a previous <strong>bpf</strong>(2) system call.</p>
</dd>
<dt><strong>PERF_EVENT_IOC_PAUSE_OUTPUT</strong> (since Linux 4.7)</dt>
<dd><p>This allows pausing and resuming the event's ring-buffer. A paused ring-buffer does not prevent generation of samples, but simply discards them. The discarded samples are considered lost, and cause a <strong>PERF_RECORD_LOST</strong> sample to be generated when possible. An overflow signal may still be triggered by the discarded sample even though the ring-buffer remains empty.</p>
<p>The argument is an unsigned 32-bit integer. A nonzero value pauses the ring-buffer, while a zero value resumes the ring-buffer.</p>
</dd>
<dt><strong>PERF_EVENT_MODIFY_ATTRIBUTES</strong> (since Linux 4.17)</dt>
<dd><p>This allows modifying an existing event without the overhead of closing and reopening a new event. Currently this is supported only for breakpoint events.</p>
<p>The argument is a pointer to a <em>perf_event_attr</em> structure containing the updated event settings.</p>
</dd>
<dt><strong>PERF_EVENT_IOC_QUERY_BPF</strong> (since Linux 4.16)</dt>
<dd><p>This allows querying which Berkeley Packet Filter (BPF) programs are attached to an existing kprobe tracepoint. You can only attach one BPF program per event, but you can have multiple events attached to a tracepoint. Querying this value on one tracepoint event returns the ID of all BPF programs in all events attached to the tracepoint. You need <strong>CAP_PERFMON</strong> (since Linux 5.8) or <strong>CAP_SYS_ADMIN</strong> privileges to use this ioctl.</p>
<p>The argument is a pointer to a structure</p>
</dd>
</dl>
<pre><code>struct perf_event_query_bpf {
    __u32    ids_len;
    __u32    prog_cnt;
    __u32    ids[0];
};</code></pre>
<blockquote>
<p>The <em>ids_len</em> field indicates the number of ids that can fit in the provided <em>ids</em> array. The <em>prog_cnt</em> value is filled in by the kernel with the number of attached BPF programs. The <em>ids</em> array is filled with the ID of each attached BPF program. If there are more programs than will fit in the array, then the kernel will return <strong>ENOSPC</strong> and <em>ids_len</em> will indicate the number of program IDs that were successfully copied.</p>
</blockquote>
<h2>Using prctl(2)</h2>
<p>A process can enable or disable all currently open event groups using the <strong>prctl</strong>(2) <strong>PR_TASK_PERF_EVENTS_ENABLE</strong> and <strong>PR_TASK_PERF_EVENTS_DISABLE</strong> operations. This applies only to events created locally by the calling process. This does not apply to events created by other processes attached to the calling process or inherited events from a parent process. Only group leaders are enabled and disabled, not any other members of the groups.</p>
<h2>perf_event related configuration files</h2>
<p>Files in <em>/proc/sys/kernel/</em></p>
<blockquote>
<dl>
<dt><em>/proc/sys/kernel/perf_event_paranoid</em></dt>
<dd><p>The <em>perf_event_paranoid</em> file can be set to restrict access to the performance counters.</p>
</dd>
</dl>
<blockquote>
<ol start="2" type="1">
<li><p>allow only user-space measurements (default since Linux 4.6).</p></li>
<li><p>allow both kernel and user measurements (default before Linux 4.6).</p></li>
<li><p>allow access to CPU-specific data but not raw tracepoint samples.</p></li>
</ol>
<ul>
<li><p>no restrictions.</p></li>
</ul>
</blockquote>
<blockquote>
<p>The existence of the <em>perf_event_paranoid</em> file is the official method for determining if a kernel supports <strong>perf_event_open</strong>().</p>
</blockquote>
<dl>
<dt><em>/proc/sys/kernel/perf_event_max_sample_rate</em></dt>
<dd><p>This sets the maximum sample rate. Setting this too high can allow users to sample at a rate that impacts overall machine performance and potentially lock up the machine. The default value is 100000 (samples per second).</p>
</dd>
<dt><em>/proc/sys/kernel/perf_event_max_stack</em></dt>
<dd><p>This file sets the maximum depth of stack frame entries reported when generating a call trace.</p>
</dd>
<dt><em>/proc/sys/kernel/perf_event_mlock_kb</em></dt>
<dd><p>Maximum number of pages an unprivileged user can <strong>mlock</strong>(2). The default is 516 (kB).</p>
</dd>
</dl>
</blockquote>
<p>Files in <em>/sys/bus/event_source/devices/</em></p>
<blockquote>
<p>Since Linux 2.6.34, the kernel supports having multiple PMUs available for monitoring. Information on how to program these PMUs can be found under <em>/sys/bus/event_source/devices/</em>. Each subdirectory corresponds to a different PMU.</p>
<dl>
<dt><em>/sys/bus/event_source/devices/*/type</em> (since Linux 2.6.38)</dt>
<dd><p>This contains an integer that can be used in the <em>type</em> field of <em>perf_event_attr</em> to indicate that you wish to use this PMU.</p>
</dd>
<dt><em>/sys/bus/event_source/devices/cpu/rdpmc</em> (since Linux 3.4)</dt>
<dd><p>If this file is 1, then direct user-space access to the performance counter registers is allowed via the rdpmc instruction. This can be disabled by echoing 0 to the file.</p>
<p>As of Linux 4.0 the behavior has changed, so that 1 now means only allow access to processes with active perf events, with 2 indicating the old allow-anyone-access behavior.</p>
</dd>
<dt><em>/sys/bus/event_source/devices/*/format/</em> (since Linux 3.4)</dt>
<dd><p>This subdirectory contains information on the architecture-specific subfields available for programming the various <em>config</em> fields in the <em>perf_event_attr</em> struct.</p>
<p>The content of each file is the name of the config field, followed by a colon, followed by a series of integer bit ranges separated by commas. For example, the file <em>event</em> may contain the value <em>config1:1,6-10,44</em> which indicates that event is an attribute that occupies bits 1,6–10, and 44 of <em>perf_event_attr::config1</em>.</p>
</dd>
<dt><em>/sys/bus/event_source/devices/*/events/</em> (since Linux 3.4)</dt>
<dd><p>This subdirectory contains files with predefined events. The contents are strings describing the event settings expressed in terms of the fields found in the previously mentioned <em>./format/</em> directory. These are not necessarily complete lists of all events supported by a PMU, but usually a subset of events deemed useful or interesting.</p>
<p>The content of each file is a list of attribute names separated by commas. Each entry has an optional value (either hex or decimal). If no value is specified, then it is assumed to be a single-bit field with a value of 1. An example entry may look like this: <em>event=0x2,inv,ldlat=3</em>.</p>
</dd>
<dt><em>/sys/bus/event_source/devices/*/uevent</em></dt>
<dd><p>This file is the standard kernel device interface for injecting hotplug events.</p>
</dd>
<dt><em>/sys/bus/event_source/devices/*/cpumask</em> (since Linux 3.7)</dt>
<dd><p>The <em>cpumask</em> file contains a comma-separated list of integers that indicate a representative CPU number for each socket (package) on the motherboard. This is needed when setting up uncore or northbridge events, as those PMUs present socket-wide events.</p>
</dd>
</dl>
</blockquote>
<h1>RETURN VALUE</h1>
<p><strong>perf_event_open</strong>() returns the new file descriptor, or -1 if an error occurred (in which case, <em>errno</em> is set appropriately).</p>
<h1>ERRORS</h1>
<p>The errors returned by <strong>perf_event_open</strong>() can be inconsistent, and may vary across processor architectures and performance monitoring units.</p>
<dl>
<dt><strong>E2BIG</strong></dt>
<dd><p>Returned if the <em>perf_event_attr</em> <em>size</em> value is too small (smaller than <strong>PERF_ATTR_SIZE_VER0</strong>), too big (larger than the page size), or larger than the kernel supports and the extra bytes are not zero. When <strong>E2BIG</strong> is returned, the <em>perf_event_attr</em> <em>size</em> field is overwritten by the kernel to be the size of the structure it was expecting.</p>
</dd>
<dt><strong>EACCES</strong></dt>
<dd><p>Returned when the requested event requires <strong>CAP_PERFMON</strong> (since Linux 5.8) or <strong>CAP_SYS_ADMIN</strong> permissions (or a more permissive perf_event paranoid setting). Some common cases where an unprivileged process may encounter this error: attaching to a process owned by a different user; monitoring all processes on a given CPU (i.e., specifying the <em>pid</em> argument as -1); and not setting <em>exclude_kernel</em> when the paranoid setting requires it.</p>
</dd>
<dt><strong>EBADF</strong></dt>
<dd><p>Returned if the <em>group_fd</em> file descriptor is not valid, or, if <strong>PERF_FLAG_PID_CGROUP</strong> is set, the cgroup file descriptor in <em>pid</em> is not valid.</p>
</dd>
<dt><strong>EBUSY</strong> (since Linux 4.1)</dt>
<dd><p>Returned if another event already has exclusive access to the PMU.</p>
</dd>
<dt><strong>EFAULT</strong></dt>
<dd><p>Returned if the <em>attr</em> pointer points at an invalid memory address.</p>
</dd>
<dt><strong>EINVAL</strong></dt>
<dd><p>Returned if the specified event is invalid. There are many possible reasons for this. A not-exhaustive list: <em>sample_freq</em> is higher than the maximum setting; the <em>cpu</em> to monitor does not exist; <em>read_format</em> is out of range; <em>sample_type</em> is out of range; the <em>flags</em> value is out of range; <em>exclusive</em> or <em>pinned</em> set and the event is not a group leader; the event <em>config</em> values are out of range or set reserved bits; the generic event selected is not supported; or there is not enough room to add the selected event.</p>
</dd>
<dt><strong>EINTR</strong></dt>
<dd><p>Returned when trying to mix perf and ftrace handling for a uprobe.</p>
</dd>
<dt><strong>EMFILE</strong></dt>
<dd><p>Each opened event uses one file descriptor. If a large number of events are opened, the per-process limit on the number of open file descriptors will be reached, and no more events can be created.</p>
</dd>
<dt><strong>ENODEV</strong></dt>
<dd><p>Returned when the event involves a feature not supported by the current CPU.</p>
</dd>
<dt><strong>ENOENT</strong></dt>
<dd><p>Returned if the <em>type</em> setting is not valid. This error is also returned for some unsupported generic events.</p>
</dd>
<dt><strong>ENOSPC</strong></dt>
<dd><p>Prior to Linux 3.3, if there was not enough room for the event, <strong>ENOSPC</strong> was returned. In Linux 3.3, this was changed to <strong>EINVAL</strong>. <strong>ENOSPC</strong> is still returned if you try to add more breakpoint events than supported by the hardware.</p>
</dd>
<dt><strong>ENOSYS</strong></dt>
<dd><p>Returned if <strong>PERF_SAMPLE_STACK_USER</strong> is set in <em>sample_type</em> and it is not supported by hardware.</p>
</dd>
<dt><strong>EOPNOTSUPP</strong></dt>
<dd><p>Returned if an event requiring a specific hardware feature is requested but there is no hardware support. This includes requesting low-skid events if not supported, branch tracing if it is not available, sampling if no PMU interrupt is available, and branch stacks for software events.</p>
</dd>
<dt><strong>EOVERFLOW</strong> (since Linux 4.8)</dt>
<dd><p>Returned if <strong>PERF_SAMPLE_CALLCHAIN</strong> is requested and <em>sample_max_stack</em> is larger than the maximum specified in <em>/proc/sys/kernel/perf_event_max_stack</em>.</p>
</dd>
<dt><strong>EPERM</strong></dt>
<dd><p>Returned on many (but not all) architectures when an unsupported <em>exclude_hv</em>, <em>exclude_idle</em>, <em>exclude_user</em>, or <em>exclude_kernel</em> setting is specified.</p>
<p>It can also happen, as with <strong>EACCES</strong>, when the requested event requires <strong>CAP_PERFMON</strong> (since Linux 5.8) or <strong>CAP_SYS_ADMIN</strong> permissions (or a more permissive perf_event paranoid setting). This includes setting a breakpoint on a kernel address, and (since Linux 3.13) setting a kernel function-trace tracepoint.</p>
</dd>
<dt><strong>ESRCH</strong></dt>
<dd><p>Returned if attempting to attach to a process that does not exist.</p>
</dd>
</dl>
<h1>VERSION</h1>
<p><strong>perf_event_open</strong>() was introduced in Linux 2.6.31 but was called <strong>perf_counter_open</strong>(). It was renamed in Linux 2.6.32.</p>
<h1>CONFORMING TO</h1>
<p>This <strong>perf_event_open</strong>() system call Linux-specific and should not be used in programs intended to be portable.</p>
<h1>NOTES</h1>
<p>Glibc does not provide a wrapper for this system call; call it using <strong>syscall</strong>(2). See the example below.</p>
<p>The official way of knowing if <strong>perf_event_open</strong>() support is enabled is checking for the existence of the file <em>/proc/sys/kernel/perf_event_paranoid</em>.</p>
<p><strong>CAP_PERFMON</strong> capability (since Linux 5.8) provides secure approach to performance monitoring and observability operations in a system according to the principal of least privilege (POSIX IEEE 1003.1e). Accessing system performance monitoring and observability operations using <strong>CAP_PERFMON</strong> rather than the much more powerful <strong>CAP_SYS_ADMIN</strong> excludes chances to misuse credentials and makes operations more secure. <strong>CAP_SYS_ADMIN</strong> usage for secure system performance monitoring and observability is discouraged in favor of the <strong>CAP_PERFMON</strong> capability.</p>
<h1>BUGS</h1>
<p>The <strong>F_SETOWN_EX</strong> option to <strong>fcntl</strong>(2) is needed to properly get overflow signals in threads. This was introduced in Linux 2.6.32.</p>
<p>Prior to Linux 2.6.33 (at least for x86), the kernel did not check if events could be scheduled together until read time. The same happens on all known kernels if the NMI watchdog is enabled. This means to see if a given set of events works you have to <strong>perf_event_open</strong>(), start, then read before you know for sure you can get valid measurements.</p>
<p>Prior to Linux 2.6.34, event constraints were not enforced by the kernel. In that case, some events would silently return "0" if the kernel scheduled them in an improper counter slot.</p>
<p>Prior to Linux 2.6.34, there was a bug when multiplexing where the wrong results could be returned.</p>
<p>Kernels from Linux 2.6.35 to Linux 2.6.39 can quickly crash the kernel if "inherit" is enabled and many threads are started.</p>
<p>Prior to Linux 2.6.35, <strong>PERF_FORMAT_GROUP</strong> did not work with attached processes.</p>
<p>There is a bug in the kernel code between Linux 2.6.36 and Linux 3.0 that ignores the "watermark" field and acts as if a wakeup_event was chosen if the union has a nonzero value in it.</p>
<p>From Linux 2.6.31 to Linux 3.4, the <strong>PERF_IOC_FLAG_GROUP</strong> ioctl argument was broken and would repeatedly operate on the event specified rather than iterating across all sibling events in a group.</p>
<p>From Linux 3.4 to Linux 3.11, the mmap <em>cap_usr_rdpmc</em> and <em>cap_usr_time</em> bits mapped to the same location. Code should migrate to the new <em>cap_user_rdpmc</em> and <em>cap_user_time</em> fields instead.</p>
<p>Always double-check your results! Various generalized events have had wrong values. For example, retired branches measured the wrong thing on AMD machines until Linux 2.6.35.</p>
<h1>EXAMPLES</h1>
<p>The following is a short example that measures the total instruction count of a call to <strong>printf</strong>(3).</p>
<pre><code>#include &lt;stdlib.h&gt;
#include &lt;stdio.h&gt;
#include &lt;unistd.h&gt;
#include &lt;string.h&gt;
#include &lt;sys/ioctl.h&gt;
#include &lt;linux/perf_event.h&gt;
#include &lt;asm/unistd.h&gt;

static long
perf_event_open(struct perf_event_attr *hw_event, pid_t pid,
                int cpu, int group_fd, unsigned long flags)
{
    int ret;

    ret = syscall(__NR_perf_event_open, hw_event, pid, cpu,
                   group_fd, flags);
    return ret;
}

int
main(int argc, char **argv)
{
    struct perf_event_attr pe;
    long long count;
    int fd;

    memset(&amp;pe, 0, sizeof(pe));
    pe.type = PERF_TYPE_HARDWARE;
    pe.size = sizeof(pe);
    pe.config = PERF_COUNT_HW_INSTRUCTIONS;
    pe.disabled = 1;
    pe.exclude_kernel = 1;
    pe.exclude_hv = 1;

    fd = perf_event_open(&amp;pe, 0, -1, -1, 0);
    if (fd == -1) {
       fprintf(stderr, &quot;Error opening leader %llx\n&quot;, pe.config);
       exit(EXIT_FAILURE);
    }

    ioctl(fd, PERF_EVENT_IOC_RESET, 0);
    ioctl(fd, PERF_EVENT_IOC_ENABLE, 0);

    printf(&quot;Measuring instruction count for this printf\n&quot;);

    ioctl(fd, PERF_EVENT_IOC_DISABLE, 0);
    read(fd, &amp;count, sizeof(count));

    printf(&quot;Used %lld instructions\n&quot;, count);

    close(fd);
}</code></pre>
<h1>SEE ALSO</h1>
<p><strong>perf</strong>(1), <strong>fcntl</strong>(2), <strong>mmap</strong>(2), <strong>open</strong>(2), <strong>prctl</strong>(2), <strong>read</strong>(2)</p>
<p><em>Documentation/admin-guide/perf-security.rst</em> in the kernel source tree</p>
<h1>COLOPHON</h1>
<p>This page is part of release 5.10 of the Linux <em>man-pages</em> project. A description of the project, information about reporting bugs, and the latest version of this page, can be found at https://www.kernel.org/doc/man-pages/.</p>
<footer style="text-align: center;"><a href="https://blog.tamer.pw" target="_blank">Blog</a> | <a href="https://github.com/linuxtamer" target="_blank">Contact</a></footer>
</div>
</body>
</html>

