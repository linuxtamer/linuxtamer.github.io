<!DOCTYPE html>
<html lang=en-US>
<head>
<meta charset=utf-8>
<title>Linux command epoll</title><meta name="description" content="Linux command epoll I/O event notification facility"><meta name="keywords" content="linux, command, epoll, bsd, I/O event notification facility"><meta name="robots" content="index,follow">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
<div class="container">

<h1>NAME</h1>
<p>epoll - I/O event notification facility</p>
<h1>SYNOPSIS</h1>
<p><strong>#include &lt;sys/epoll.h&gt;</strong></p>
<h1>DESCRIPTION</h1>
<p>The <strong>epoll</strong> API performs a similar task to <strong>poll</strong>(2): monitoring multiple file descriptors to see if I/O is possible on any of them. The <strong>epoll</strong> API can be used either as an edge-triggered or a level-triggered interface and scales well to large numbers of watched file descriptors.</p>
<p>The central concept of the <strong>epoll</strong> API is the <strong>epoll</strong> <em>instance</em>, an in-kernel data structure which, from a user-space perspective, can be considered as a container for two lists:</p>
<ul>
<li><p>The <em>interest</em> list (sometimes also called the <strong>epoll</strong> set): the set of file descriptors that the process has registered an interest in monitoring.</p></li>
<li><p>The <em>ready</em> list: the set of file descriptors that are "ready" for I/O. The ready list is a subset of (or, more precisely, a set of references to) the file descriptors in the interest list. The ready list is dynamically populated by the kernel as a result of I/O activity on those file descriptors.</p></li>
</ul>
<p>The following system calls are provided to create and manage an <strong>epoll</strong> instance:</p>
<ul>
<li><p><strong>epoll_create</strong>(2) creates a new <strong>epoll</strong> instance and returns a file descriptor referring to that instance. (The more recent <strong>epoll_create1</strong>(2) extends the functionality of <strong>epoll_create</strong>(2).)</p></li>
<li><p>Interest in particular file descriptors is then registered via <strong>epoll_ctl</strong>(2), which adds items to the interest list of the <strong>epoll</strong> instance.</p></li>
<li><p><strong>epoll_wait</strong>(2) waits for I/O events, blocking the calling thread if no events are currently available. (This system call can be thought of as fetching items from the ready list of the <strong>epoll</strong> instance.)</p></li>
</ul>
<h2>Level-triggered and edge-triggered</h2>
<p>The <strong>epoll</strong> event distribution interface is able to behave both as edge-triggered (ET) and as level-triggered (LT). The difference between the two mechanisms can be described as follows. Suppose that this scenario happens:</p>
<ol type="1">
<li><p>The file descriptor that represents the read side of a pipe (<em>rfd</em>) is registered on the <strong>epoll</strong> instance.</p></li>
<li><p>A pipe writer writes 2 kB of data on the write side of the pipe.</p></li>
<li><p>A call to <strong>epoll_wait</strong>(2) is done that will return <em>rfd</em> as a ready file descriptor.</p></li>
<li><p>The pipe reader reads 1 kB of data from <em>rfd</em>.</p></li>
<li><p>A call to <strong>epoll_wait</strong>(2) is done.</p></li>
</ol>
<p>If the <em>rfd</em> file descriptor has been added to the <strong>epoll</strong> interface using the <strong>EPOLLET</strong> (edge-triggered) flag, the call to <strong>epoll_wait</strong>(2) done in step <strong>5</strong> will probably hang despite the available data still present in the file input buffer; meanwhile the remote peer might be expecting a response based on the data it already sent. The reason for this is that edge-triggered mode delivers events only when changes occur on the monitored file descriptor. So, in step <strong>5</strong> the caller might end up waiting for some data that is already present inside the input buffer. In the above example, an event on <em>rfd</em> will be generated because of the write done in <strong>2</strong> and the event is consumed in <strong>3</strong>. Since the read operation done in <strong>4</strong> does not consume the whole buffer data, the call to <strong>epoll_wait</strong>(2) done in step <strong>5</strong> might block indefinitely.</p>
<p>An application that employs the <strong>EPOLLET</strong> flag should use nonblocking file descriptors to avoid having a blocking read or write starve a task that is handling multiple file descriptors. The suggested way to use <strong>epoll</strong> as an edge-triggered (<strong>EPOLLET</strong>) interface is as follows:</p>
<ol type="a">
<li><p>with nonblocking file descriptors; and</p></li>
<li><p>by waiting for an event only after <strong>read</strong>(2) or <strong>write</strong>(2) return <strong>EAGAIN</strong>.</p></li>
</ol>
<p>By contrast, when used as a level-triggered interface (the default, when <strong>EPOLLET</strong> is not specified), <strong>epoll</strong> is simply a faster <strong>poll</strong>(2), and can be used wherever the latter is used since it shares the same semantics.</p>
<p>Since even with edge-triggered <strong>epoll</strong>, multiple events can be generated upon receipt of multiple chunks of data, the caller has the option to specify the <strong>EPOLLONESHOT</strong> flag, to tell <strong>epoll</strong> to disable the associated file descriptor after the receipt of an event with <strong>epoll_wait</strong>(2). When the <strong>EPOLLONESHOT</strong> flag is specified, it is the caller's responsibility to rearm the file descriptor using <strong>epoll_ctl</strong>(2) with <strong>EPOLL_CTL_MOD</strong>.</p>
<p>If multiple threads (or processes, if child processes have inherited the <strong>epoll</strong> file descriptor across <strong>fork</strong>(2)) are blocked in <strong>epoll_wait</strong>(2) waiting on the same epoll file descriptor and a file descriptor in the interest list that is marked for edge-triggered (<strong>EPOLLET</strong>) notification becomes ready, just one of the threads (or processes) is awoken from <strong>epoll_wait</strong>(2). This provides a useful optimization for avoiding "thundering herd" wake-ups in some scenarios.</p>
<h2>Interaction with autosleep</h2>
<p>If the system is in <strong>autosleep</strong> mode via <em>/sys/power/autosleep</em> and an event happens which wakes the device from sleep, the device driver will keep the device awake only until that event is queued. To keep the device awake until the event has been processed, it is necessary to use the <strong>epoll_ctl</strong>(2) <strong>EPOLLWAKEUP</strong> flag.</p>
<p>When the <strong>EPOLLWAKEUP</strong> flag is set in the <strong>events</strong> field for a <em>struct epoll_event</em>, the system will be kept awake from the moment the event is queued, through the <strong>epoll_wait</strong>(2) call which returns the event until the subsequent <strong>epoll_wait</strong>(2) call. If the event should keep the system awake beyond that time, then a separate <em>wake_lock</em> should be taken before the second <strong>epoll_wait</strong>(2) call.</p>
<h2>/proc interfaces</h2>
<p>The following interfaces can be used to limit the amount of kernel memory consumed by epoll:</p>
<dl>
<dt><em>/proc/sys/fs/epoll/max_user_watches</em> (since Linux 2.6.28)</dt>
<dd><p>This specifies a limit on the total number of file descriptors that a user can register across all epoll instances on the system. The limit is per real user ID. Each registered file descriptor costs roughly 90 bytes on a 32-bit kernel, and roughly 160 bytes on a 64-bit kernel. Currently, the default value for <em>max_user_watches</em> is 1/25 (4%) of the available low memory, divided by the registration cost in bytes.</p>
</dd>
</dl>
<h2>Example for suggested usage</h2>
<p>While the usage of <strong>epoll</strong> when employed as a level-triggered interface does have the same semantics as <strong>poll</strong>(2), the edge-triggered usage requires more clarification to avoid stalls in the application event loop. In this example, listener is a nonblocking socket on which <strong>listen</strong>(2) has been called. The function <em>do_use_fd()</em> uses the new ready file descriptor until <strong>EAGAIN</strong> is returned by either <strong>read</strong>(2) or <strong>write</strong>(2). An event-driven state machine application should, after having received <strong>EAGAIN</strong>, record its current state so that at the next call to <em>do_use_fd()</em> it will continue to <strong>read</strong>(2) or <strong>write</strong>(2) from where it stopped before.</p>
<pre><code>#define MAX_EVENTS 10
struct epoll_event ev, events[MAX_EVENTS];
int listen_sock, conn_sock, nfds, epollfd;

/* Code to set up listening socket, &#39;listen_sock&#39;,
   (socket(), bind(), listen()) omitted */

epollfd = epoll_create1(0);
if (epollfd == -1) {
    perror(&quot;epoll_create1&quot;);
    exit(EXIT_FAILURE);
}

ev.events = EPOLLIN;
ev.data.fd = listen_sock;
if (epoll_ctl(epollfd, EPOLL_CTL_ADD, listen_sock, &amp;ev) == -1) {
    perror(&quot;epoll_ctl: listen_sock&quot;);
    exit(EXIT_FAILURE);
}

for (;;) {
    nfds = epoll_wait(epollfd, events, MAX_EVENTS, -1);
    if (nfds == -1) {
        perror(&quot;epoll_wait&quot;);
        exit(EXIT_FAILURE);
    }

    for (n = 0; n &lt; nfds; ++n) {
        if (events[n].data.fd == listen_sock) {
            conn_sock = accept(listen_sock,
                               (struct sockaddr *) &amp;addr, &amp;addrlen);
            if (conn_sock == -1) {
                perror(&quot;accept&quot;);
                exit(EXIT_FAILURE);
            }
            setnonblocking(conn_sock);
            ev.events = EPOLLIN | EPOLLET;
            ev.data.fd = conn_sock;
            if (epoll_ctl(epollfd, EPOLL_CTL_ADD, conn_sock,
                        &amp;ev) == -1) {
                perror(&quot;epoll_ctl: conn_sock&quot;);
                exit(EXIT_FAILURE);
            }
        } else {
            do_use_fd(events[n].data.fd);
        }
    }
}</code></pre>
<p>When used as an edge-triggered interface, for performance reasons, it is possible to add the file descriptor inside the <strong>epoll</strong> interface (<strong>EPOLL_CTL_ADD</strong>) once by specifying (<strong>EPOLLIN</strong>|<strong>EPOLLOUT</strong>). This allows you to avoid continuously switching between <strong>EPOLLIN</strong> and <strong>EPOLLOUT</strong> calling <strong>epoll_ctl</strong>(2) with <strong>EPOLL_CTL_MOD</strong>.</p>
<h2>Questions and answers</h2>
<ol start="0" type="1">
<li><p>What is the key used to distinguish the file descriptors registered in an interest list?</p>
<p>The key is the combination of the file descriptor number and the open file description (also known as an "open file handle", the kernel's internal representation of an open file).</p></li>
<li><p>What happens if you register the same file descriptor on an <strong>epoll</strong> instance twice?</p>
<p>You will probably get <strong>EEXIST</strong>. However, it is possible to add a duplicate (<strong>dup</strong>(2), <strong>dup2</strong>(2), <strong>fcntl</strong>(2) <strong>F_DUPFD</strong>) file descriptor to the same <strong>epoll</strong> instance. This can be a useful technique for filtering events, if the duplicate file descriptors are registered with different <em>events</em> masks.</p></li>
<li><p>Can two <strong>epoll</strong> instances wait for the same file descriptor? If so, are events reported to both <strong>epoll</strong> file descriptors?</p>
<p>Yes, and events would be reported to both. However, careful programming may be needed to do this correctly.</p></li>
<li><p>Is the <strong>epoll</strong> file descriptor itself poll/epoll/selectable?</p>
<p>Yes. If an <strong>epoll</strong> file descriptor has events waiting, then it will indicate as being readable.</p></li>
<li><p>What happens if one attempts to put an <strong>epoll</strong> file descriptor into its own file descriptor set?</p>
<p>The <strong>epoll_ctl</strong>(2) call fails (<strong>EINVAL</strong>). However, you can add an <strong>epoll</strong> file descriptor inside another <strong>epoll</strong> file descriptor set.</p></li>
<li><p>Can I send an <strong>epoll</strong> file descriptor over a UNIX domain socket to another process?</p>
<p>Yes, but it does not make sense to do this, since the receiving process would not have copies of the file descriptors in the interest list.</p></li>
<li><p>Will closing a file descriptor cause it to be removed from all <strong>epoll</strong> interest lists?</p>
<p>Yes, but be aware of the following point. A file descriptor is a reference to an open file description (see <strong>open</strong>(2)). Whenever a file descriptor is duplicated via <strong>dup</strong>(2), <strong>dup2</strong>(2), <strong>fcntl</strong>(2) <strong>F_DUPFD</strong>, or <strong>fork</strong>(2), a new file descriptor referring to the same open file description is created. An open file description continues to exist until all file descriptors referring to it have been closed.</p>
<p>A file descriptor is removed from an interest list only after all the file descriptors referring to the underlying open file description have been closed. This means that even after a file descriptor that is part of an interest list has been closed, events may be reported for that file descriptor if other file descriptors referring to the same underlying file description remain open. To prevent this happening, the file descriptor must be explicitly removed from the interest list (using <strong>epoll_ctl</strong>(2) <strong>EPOLL_CTL_DEL</strong>) before it is duplicated. Alternatively, the application must ensure that all file descriptors are closed (which may be difficult if file descriptors were duplicated behind the scenes by library functions that used <strong>dup</strong>(2) or <strong>fork</strong>(2)).</p></li>
<li><p>If more than one event occurs between <strong>epoll_wait</strong>(2) calls, are they combined or reported separately?</p>
<p>They will be combined.</p></li>
<li><p>Does an operation on a file descriptor affect the already collected but not yet reported events?</p>
<p>You can do two operations on an existing file descriptor. Remove would be meaningless for this case. Modify will reread available I/O.</p></li>
<li><p>Do I need to continuously read/write a file descriptor until <strong>EAGAIN</strong> when using the <strong>EPOLLET</strong> flag (edge-triggered behavior)?</p>
<p>Receiving an event from <strong>epoll_wait</strong>(2) should suggest to you that such file descriptor is ready for the requested I/O operation. You must consider it ready until the next (nonblocking) read/write yields <strong>EAGAIN</strong>. When and how you will use the file descriptor is entirely up to you.</p>
<p>For packet/token-oriented files (e.g., datagram socket, terminal in canonical mode), the only way to detect the end of the read/write I/O space is to continue to read/write until <strong>EAGAIN</strong>.</p>
<p>For stream-oriented files (e.g., pipe, FIFO, stream socket), the condition that the read/write I/O space is exhausted can also be detected by checking the amount of data read from / written to the target file descriptor. For example, if you call <strong>read</strong>(2) by asking to read a certain amount of data and <strong>read</strong>(2) returns a lower number of bytes, you can be sure of having exhausted the read I/O space for the file descriptor. The same is true when writing using <strong>write</strong>(2). (Avoid this latter technique if you cannot guarantee that the monitored file descriptor always refers to a stream-oriented file.)</p></li>
</ol>
<h2>Possible pitfalls and ways to avoid them</h2>
<dl>
<dt><strong>o Starvation (edge-triggered)</strong></dt>
<dd>
</dd>
</dl>
<p>If there is a large amount of I/O space, it is possible that by trying to drain it the other files will not get processed causing starvation. (This problem is not specific to <strong>epoll</strong>.)</p>
<p>The solution is to maintain a ready list and mark the file descriptor as ready in its associated data structure, thereby allowing the application to remember which files need to be processed but still round robin amongst all the ready files. This also supports ignoring subsequent events you receive for file descriptors that are already ready.</p>
<dl>
<dt><strong>o If using an event cache...</strong></dt>
<dd>
</dd>
</dl>
<p>If you use an event cache or store all the file descriptors returned from <strong>epoll_wait</strong>(2), then make sure to provide a way to mark its closure dynamically (i.e., caused by a previous event's processing). Suppose you receive 100 events from <strong>epoll_wait</strong>(2), and in event #47 a condition causes event #13 to be closed. If you remove the structure and <strong>close</strong>(2) the file descriptor for event #13, then your event cache might still say there are events waiting for that file descriptor causing confusion.</p>
<p>One solution for this is to call, during the processing of event 47, <strong>epoll_ctl</strong>(<strong>EPOLL_CTL_DEL</strong>) to delete file descriptor 13 and <strong>close</strong>(2), then mark its associated data structure as removed and link it to a cleanup list. If you find another event for file descriptor 13 in your batch processing, you will discover the file descriptor had been previously removed and there will be no confusion.</p>
<h1>VERSIONS</h1>
<p>The <strong>epoll</strong> API was introduced in Linux kernel 2.5.44. Support was added to glibc in version 2.3.2.</p>
<h1>CONFORMING TO</h1>
<p>The <strong>epoll</strong> API is Linux-specific. Some other systems provide similar mechanisms, for example, FreeBSD has <em>kqueue</em>, and Solaris has <em>/dev/poll</em>.</p>
<h1>NOTES</h1>
<p>The set of file descriptors that is being monitored via an epoll file descriptor can be viewed via the entry for the epoll file descriptor in the process's <em>/proc/[pid]/fdinfo</em> directory. See <strong>proc</strong>(5) for further details.</p>
<p>The <strong>kcmp</strong>(2) <strong>KCMP_EPOLL_TFD</strong> operation can be used to test whether a file descriptor is present in an epoll instance.</p>
<h1>SEE ALSO</h1>
<p><strong>epoll_create</strong>(2), <strong>epoll_create1</strong>(2), <strong>epoll_ctl</strong>(2), <strong>epoll_wait</strong>(2), <strong>poll</strong>(2), <strong>select</strong>(2)</p>
<h1>COLOPHON</h1>
<p>This page is part of release 5.10 of the Linux <em>man-pages</em> project. A description of the project, information about reporting bugs, and the latest version of this page, can be found at https://www.kernel.org/doc/man-pages/.</p>
<footer style="text-align: center;"><a href="https://blog.tamer.pw" target="_blank">Blog</a> | <a href="https://github.com/linuxtamer" target="_blank">Contact</a></footer>
</div>
</body>
</html>

