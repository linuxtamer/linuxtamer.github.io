<!DOCTYPE html>
<html lang=en-US>
<head>
<meta charset=utf-8>
<title>Linux command sched</title><meta name="description" content="Linux command sched overview of CPU scheduling"><meta name="keywords" content="linux, command, sched, bsd, overview of CPU scheduling"><meta name="robots" content="index,follow">
<meta name="viewport" content="width=device-width, initial-scale=1">
</head>
<body>
<div class="container">

<h1>NAME</h1>
<p>sched - overview of CPU scheduling</p>
<h1>DESCRIPTION</h1>
<p>Since Linux 2.6.23, the default scheduler is CFS, the "Completely Fair Scheduler". The CFS scheduler replaced the earlier "O(1)" scheduler.</p>
<h2>API summary</h2>
<p>Linux provides the following system calls for controlling the CPU scheduling behavior, policy, and priority of processes (or, more precisely, threads).</p>
<dl>
<dt><strong>nice</strong>(2)</dt>
<dd><p>Set a new nice value for the calling thread, and return the new nice value.</p>
</dd>
<dt><strong>getpriority</strong>(2)</dt>
<dd><p>Return the nice value of a thread, a process group, or the set of threads owned by a specified user.</p>
</dd>
<dt><strong>setpriority</strong>(2)</dt>
<dd><p>Set the nice value of a thread, a process group, or the set of threads owned by a specified user.</p>
</dd>
<dt><strong>sched_setscheduler</strong>(2)</dt>
<dd><p>Set the scheduling policy and parameters of a specified thread.</p>
</dd>
<dt><strong>sched_getscheduler</strong>(2)</dt>
<dd><p>Return the scheduling policy of a specified thread.</p>
</dd>
<dt><strong>sched_setparam</strong>(2)</dt>
<dd><p>Set the scheduling parameters of a specified thread.</p>
</dd>
<dt><strong>sched_getparam</strong>(2)</dt>
<dd><p>Fetch the scheduling parameters of a specified thread.</p>
</dd>
<dt><strong>sched_get_priority_max</strong>(2)</dt>
<dd><p>Return the maximum priority available in a specified scheduling policy.</p>
</dd>
<dt><strong>sched_get_priority_min</strong>(2)</dt>
<dd><p>Return the minimum priority available in a specified scheduling policy.</p>
</dd>
<dt><strong>sched_rr_get_interval</strong>(2)</dt>
<dd><p>Fetch the quantum used for threads that are scheduled under the "round-robin" scheduling policy.</p>
</dd>
<dt><strong>sched_yield</strong>(2)</dt>
<dd><p>Cause the caller to relinquish the CPU, so that some other thread be executed.</p>
</dd>
<dt><strong>sched_setaffinity</strong>(2)</dt>
<dd><p>(Linux-specific) Set the CPU affinity of a specified thread.</p>
</dd>
<dt><strong>sched_getaffinity</strong>(2)</dt>
<dd><p>(Linux-specific) Get the CPU affinity of a specified thread.</p>
</dd>
<dt><strong>sched_setattr</strong>(2)</dt>
<dd><p>Set the scheduling policy and parameters of a specified thread. This (Linux-specific) system call provides a superset of the functionality of <strong>sched_setscheduler</strong>(2) and <strong>sched_setparam</strong>(2).</p>
</dd>
<dt><strong>sched_getattr</strong>(2)</dt>
<dd><p>Fetch the scheduling policy and parameters of a specified thread. This (Linux-specific) system call provides a superset of the functionality of <strong>sched_getscheduler</strong>(2) and <strong>sched_getparam</strong>(2).</p>
</dd>
</dl>
<h2>Scheduling policies</h2>
<p>The scheduler is the kernel component that decides which runnable thread will be executed by the CPU next. Each thread has an associated scheduling policy and a <em>static</em> scheduling priority, <em>sched_priority</em>. The scheduler makes its decisions based on knowledge of the scheduling policy and static priority of all threads on the system.</p>
<p>For threads scheduled under one of the normal scheduling policies (<strong>SCHED_OTHER</strong>, <strong>SCHED_IDLE</strong>, <strong>SCHED_BATCH</strong>), <em>sched_priority</em> is not used in scheduling decisions (it must be specified as 0).</p>
<p>Processes scheduled under one of the real-time policies (<strong>SCHED_FIFO</strong>, <strong>SCHED_RR</strong>) have a <em>sched_priority</em> value in the range 1 (low) to 99 (high). (As the numbers imply, real-time threads always have higher priority than normal threads.) Note well: POSIX.1 requires an implementation to support only a minimum 32 distinct priority levels for the real-time policies, and some systems supply just this minimum. Portable programs should use <strong>sched_get_priority_min</strong>(2) and <strong>sched_get_priority_max</strong>(2) to find the range of priorities supported for a particular policy.</p>
<p>Conceptually, the scheduler maintains a list of runnable threads for each possible <em>sched_priority</em> value. In order to determine which thread runs next, the scheduler looks for the nonempty list with the highest static priority and selects the thread at the head of this list.</p>
<p>A thread's scheduling policy determines where it will be inserted into the list of threads with equal static priority and how it will move inside this list.</p>
<p>All scheduling is preemptive: if a thread with a higher static priority becomes ready to run, the currently running thread will be preempted and returned to the wait list for its static priority level. The scheduling policy determines the ordering only within the list of runnable threads with equal static priority.</p>
<h2>SCHED_FIFO: First in-first out scheduling</h2>
<p><strong>SCHED_FIFO</strong> can be used only with static priorities higher than 0, which means that when a <strong>SCHED_FIFO</strong> thread becomes runnable, it will always immediately preempt any currently running <strong>SCHED_OTHER</strong>, <strong>SCHED_BATCH</strong>, or <strong>SCHED_IDLE</strong> thread. <strong>SCHED_FIFO</strong> is a simple scheduling algorithm without time slicing. For threads scheduled under the <strong>SCHED_FIFO</strong> policy, the following rules apply:</p>
<ol type="1">
<li><p>A running <strong>SCHED_FIFO</strong> thread that has been preempted by another thread of higher priority will stay at the head of the list for its priority and will resume execution as soon as all threads of higher priority are blocked again.</p></li>
<li><p>When a blocked <strong>SCHED_FIFO</strong> thread becomes runnable, it will be inserted at the end of the list for its priority.</p></li>
<li><p>If a call to <strong>sched_setscheduler</strong>(2), <strong>sched_setparam</strong>(2), <strong>sched_setattr</strong>(2), <strong>pthread_setschedparam</strong>(3), or <strong>pthread_setschedprio</strong>(3) changes the priority of the running or runnable <strong>SCHED_FIFO</strong> thread identified by <em>pid</em> the effect on the thread's position in the list depends on the direction of the change to threads priority:</p>
<ul>
<li><p>If the thread's priority is raised, it is placed at the end of the list for its new priority. As a consequence, it may preempt a currently running thread with the same priority.</p></li>
<li><p>If the thread's priority is unchanged, its position in the run list is unchanged.</p></li>
<li><p>If the thread's priority is lowered, it is placed at the front of the list for its new priority.</p></li>
</ul>
<p>According to POSIX.1-2008, changes to a thread's priority (or policy) using any mechanism other than <strong>pthread_setschedprio</strong>(3) should result in the thread being placed at the end of the list for its priority.</p></li>
<li><p>A thread calling <strong>sched_yield</strong>(2) will be put at the end of the list.</p></li>
</ol>
<p>No other events will move a thread scheduled under the <strong>SCHED_FIFO</strong> policy in the wait list of runnable threads with equal static priority.</p>
<p>A <strong>SCHED_FIFO</strong> thread runs until either it is blocked by an I/O request, it is preempted by a higher priority thread, or it calls <strong>sched_yield</strong>(2).</p>
<h2>SCHED_RR: Round-robin scheduling</h2>
<p><strong>SCHED_RR</strong> is a simple enhancement of <strong>SCHED_FIFO</strong>. Everything described above for <strong>SCHED_FIFO</strong> also applies to <strong>SCHED_RR</strong>, except that each thread is allowed to run only for a maximum time quantum. If a <strong>SCHED_RR</strong> thread has been running for a time period equal to or longer than the time quantum, it will be put at the end of the list for its priority. A <strong>SCHED_RR</strong> thread that has been preempted by a higher priority thread and subsequently resumes execution as a running thread will complete the unexpired portion of its round-robin time quantum. The length of the time quantum can be retrieved using <strong>sched_rr_get_interval</strong>(2).</p>
<h2>SCHED_DEADLINE: Sporadic task model deadline scheduling</h2>
<p>Since version 3.14, Linux provides a deadline scheduling policy (<strong>SCHED_DEADLINE</strong>). This policy is currently implemented using GEDF (Global Earliest Deadline First) in conjunction with CBS (Constant Bandwidth Server). To set and fetch this policy and associated attributes, one must use the Linux-specific <strong>sched_setattr</strong>(2) and <strong>sched_getattr</strong>(2) system calls.</p>
<p>A sporadic task is one that has a sequence of jobs, where each job is activated at most once per period. Each job also has a <em>relative deadline</em>, before which it should finish execution, and a <em>computation time</em>, which is the CPU time necessary for executing the job. The moment when a task wakes up because a new job has to be executed is called the <em>arrival time</em> (also referred to as the request time or release time). The <em>start time</em> is the time at which a task starts its execution. The <em>absolute deadline</em> is thus obtained by adding the relative deadline to the arrival time.</p>
<p>The following diagram clarifies these terms:</p>
<pre><code>arrival/wakeup                    absolute deadline
     |    start time                    |
     |        |                         |
     v        v                         v
-----x--------xooooooooooooooooo--------x--------x---
              |&lt;- comp. time -&gt;|
     |&lt;------- relative deadline ------&gt;|
     |&lt;-------------- period -------------------&gt;|</code></pre>
<p>When setting a <strong>SCHED_DEADLINE</strong> policy for a thread using <strong>sched_setattr</strong>(2), one can specify three parameters: <em>Runtime</em>, <em>Deadline</em>, and <em>Period</em>. These parameters do not necessarily correspond to the aforementioned terms: usual practice is to set Runtime to something bigger than the average computation time (or worst-case execution time for hard real-time tasks), Deadline to the relative deadline, and Period to the period of the task. Thus, for <strong>SCHED_DEADLINE</strong> scheduling, we have:</p>
<pre><code>arrival/wakeup                    absolute deadline
     |    start time                    |
     |        |                         |
     v        v                         v
-----x--------xooooooooooooooooo--------x--------x---
              |&lt;-- Runtime -------&gt;|
     |&lt;----------- Deadline -----------&gt;|
     |&lt;-------------- Period -------------------&gt;|</code></pre>
<p>The three deadline-scheduling parameters correspond to the <em>sched_runtime</em>, <em>sched_deadline</em>, and <em>sched_period</em> fields of the <em>sched_attr</em> structure; see <strong>sched_setattr</strong>(2). These fields express values in nanoseconds. If <em>sched_period</em> is specified as 0, then it is made the same as <em>sched_deadline</em>.</p>
<p>The kernel requires that:</p>
<p>sched_runtime &lt;= sched_deadline &lt;= sched_period</p>
<p>In addition, under the current implementation, all of the parameter values must be at least 1024 (i.e., just over one microsecond, which is the resolution of the implementation), and less than 2^63. If any of these checks fails, <strong>sched_setattr</strong>(2) fails with the error <strong>EINVAL</strong>.</p>
<p>The CBS guarantees non-interference between tasks, by throttling threads that attempt to over-run their specified Runtime.</p>
<p>To ensure deadline scheduling guarantees, the kernel must prevent situations where the set of <strong>SCHED_DEADLINE</strong> threads is not feasible (schedulable) within the given constraints. The kernel thus performs an admittance test when setting or changing <strong>SCHED_DEADLINE</strong> policy and attributes. This admission test calculates whether the change is feasible; if it is not, <strong>sched_setattr</strong>(2) fails with the error <strong>EBUSY</strong>.</p>
<p>For example, it is required (but not necessarily sufficient) for the total utilization to be less than or equal to the total number of CPUs available, where, since each thread can maximally run for Runtime per Period, that thread's utilization is its Runtime divided by its Period.</p>
<p>In order to fulfill the guarantees that are made when a thread is admitted to the <strong>SCHED_DEADLINE</strong> policy, <strong>SCHED_DEADLINE</strong> threads are the highest priority (user controllable) threads in the system; if any <strong>SCHED_DEADLINE</strong> thread is runnable, it will preempt any thread scheduled under one of the other policies.</p>
<p>A call to <strong>fork</strong>(2) by a thread scheduled under the <strong>SCHED_DEADLINE</strong> policy fails with the error <strong>EAGAIN</strong>, unless the thread has its reset-on-fork flag set (see below).</p>
<p>A <strong>SCHED_DEADLINE</strong> thread that calls <strong>sched_yield</strong>(2) will yield the current job and wait for a new period to begin.</p>
<h2>SCHED_OTHER: Default Linux time-sharing scheduling</h2>
<p><strong>SCHED_OTHER</strong> can be used at only static priority 0 (i.e., threads under real-time policies always have priority over <strong>SCHED_OTHER</strong> processes). <strong>SCHED_OTHER</strong> is the standard Linux time-sharing scheduler that is intended for all threads that do not require the special real-time mechanisms.</p>
<p>The thread to run is chosen from the static priority 0 list based on a <em>dynamic</em> priority that is determined only inside this list. The dynamic priority is based on the nice value (see below) and is increased for each time quantum the thread is ready to run, but denied to run by the scheduler. This ensures fair progress among all <strong>SCHED_OTHER</strong> threads.</p>
<p>In the Linux kernel source code, the <strong>SCHED_OTHER</strong> policy is actually named <strong>SCHED_NORMAL</strong>.</p>
<h2>The nice value</h2>
<p>The nice value is an attribute that can be used to influence the CPU scheduler to favor or disfavor a process in scheduling decisions. It affects the scheduling of <strong>SCHED_OTHER</strong> and <strong>SCHED_BATCH</strong> (see below) processes. The nice value can be modified using <strong>nice</strong>(2), <strong>setpriority</strong>(2), or <strong>sched_setattr</strong>(2).</p>
<p>According to POSIX.1, the nice value is a per-process attribute; that is, the threads in a process should share a nice value. However, on Linux, the nice value is a per-thread attribute: different threads in the same process may have different nice values.</p>
<p>The range of the nice value varies across UNIX systems. On modern Linux, the range is -20 (high priority) to +19 (low priority). On some other systems, the range is -20..20. Very early Linux kernels (Before Linux 2.0) had the range -infinity..15.</p>
<p>The degree to which the nice value affects the relative scheduling of <strong>SCHED_OTHER</strong> processes likewise varies across UNIX systems and across Linux kernel versions.</p>
<p>With the advent of the CFS scheduler in kernel 2.6.23, Linux adopted an algorithm that causes relative differences in nice values to have a much stronger effect. In the current implementation, each unit of difference in the nice values of two processes results in a factor of 1.25 in the degree to which the scheduler favors the higher priority process. This causes very low nice values (+19) to truly provide little CPU to a process whenever there is any other higher priority load on the system, and makes high nice values (-20) deliver most of the CPU to applications that require it (e.g., some audio applications).</p>
<p>On Linux, the <strong>RLIMIT_NICE</strong> resource limit can be used to define a limit to which an unprivileged process's nice value can be raised; see <strong>setrlimit</strong>(2) for details.</p>
<p>For further details on the nice value, see the subsections on the autogroup feature and group scheduling, below.</p>
<h2>SCHED_BATCH: Scheduling batch processes</h2>
<p>(Since Linux 2.6.16.) <strong>SCHED_BATCH</strong> can be used only at static priority 0. This policy is similar to <strong>SCHED_OTHER</strong> in that it schedules the thread according to its dynamic priority (based on the nice value). The difference is that this policy will cause the scheduler to always assume that the thread is CPU-intensive. Consequently, the scheduler will apply a small scheduling penalty with respect to wakeup behavior, so that this thread is mildly disfavored in scheduling decisions.</p>
<p>This policy is useful for workloads that are noninteractive, but do not want to lower their nice value, and for workloads that want a deterministic scheduling policy without interactivity causing extra preemptions (between the workload's tasks).</p>
<h2>SCHED_IDLE: Scheduling very low priority jobs</h2>
<p>(Since Linux 2.6.23.) <strong>SCHED_IDLE</strong> can be used only at static priority 0; the process nice value has no influence for this policy.</p>
<p>This policy is intended for running jobs at extremely low priority (lower even than a +19 nice value with the <strong>SCHED_OTHER</strong> or <strong>SCHED_BATCH</strong> policies).</p>
<h2>Resetting scheduling policy for child processes</h2>
<p>Each thread has a reset-on-fork scheduling flag. When this flag is set, children created by <strong>fork</strong>(2) do not inherit privileged scheduling policies. The reset-on-fork flag can be set by either:</p>
<ul>
<li><p>ORing the <strong>SCHED_RESET_ON_FORK</strong> flag into the <em>policy</em> argument when calling <strong>sched_setscheduler</strong>(2) (since Linux 2.6.32); or</p></li>
<li><p>specifying the <strong>SCHED_FLAG_RESET_ON_FORK</strong> flag in <em>attr.sched_flags</em> when calling <strong>sched_setattr</strong>(2).</p></li>
</ul>
<p>Note that the constants used with these two APIs have different names. The state of the reset-on-fork flag can analogously be retrieved using <strong>sched_getscheduler</strong>(2) and <strong>sched_getattr</strong>(2).</p>
<p>The reset-on-fork feature is intended for media-playback applications, and can be used to prevent applications evading the <strong>RLIMIT_RTTIME</strong> resource limit (see <strong>getrlimit</strong>(2)) by creating multiple child processes.</p>
<p>More precisely, if the reset-on-fork flag is set, the following rules apply for subsequently created children:</p>
<ul>
<li><p>If the calling thread has a scheduling policy of <strong>SCHED_FIFO</strong> or <strong>SCHED_RR</strong>, the policy is reset to <strong>SCHED_OTHER</strong> in child processes.</p></li>
<li><p>If the calling process has a negative nice value, the nice value is reset to zero in child processes.</p></li>
</ul>
<p>After the reset-on-fork flag has been enabled, it can be reset only if the thread has the <strong>CAP_SYS_NICE</strong> capability. This flag is disabled in child processes created by <strong>fork</strong>(2).</p>
<h2>Privileges and resource limits</h2>
<p>In Linux kernels before 2.6.12, only privileged (<strong>CAP_SYS_NICE</strong>) threads can set a nonzero static priority (i.e., set a real-time scheduling policy). The only change that an unprivileged thread can make is to set the <strong>SCHED_OTHER</strong> policy, and this can be done only if the effective user ID of the caller matches the real or effective user ID of the target thread (i.e., the thread specified by <em>pid</em>) whose policy is being changed.</p>
<p>A thread must be privileged (<strong>CAP_SYS_NICE</strong>) in order to set or modify a <strong>SCHED_DEADLINE</strong> policy.</p>
<p>Since Linux 2.6.12, the <strong>RLIMIT_RTPRIO</strong> resource limit defines a ceiling on an unprivileged thread's static priority for the <strong>SCHED_RR</strong> and <strong>SCHED_FIFO</strong> policies. The rules for changing scheduling policy and priority are as follows:</p>
<ul>
<li><p>If an unprivileged thread has a nonzero <strong>RLIMIT_RTPRIO</strong> soft limit, then it can change its scheduling policy and priority, subject to the restriction that the priority cannot be set to a value higher than the maximum of its current priority and its <strong>RLIMIT_RTPRIO</strong> soft limit.</p></li>
<li><p>If the <strong>RLIMIT_RTPRIO</strong> soft limit is 0, then the only permitted changes are to lower the priority, or to switch to a non-real-time policy.</p></li>
<li><p>Subject to the same rules, another unprivileged thread can also make these changes, as long as the effective user ID of the thread making the change matches the real or effective user ID of the target thread.</p></li>
<li><p>Special rules apply for the <strong>SCHED_IDLE</strong> policy. In Linux kernels before 2.6.39, an unprivileged thread operating under this policy cannot change its policy, regardless of the value of its <strong>RLIMIT_RTPRIO</strong> resource limit. In Linux kernels since 2.6.39, an unprivileged thread can switch to either the <strong>SCHED_BATCH</strong> or the <strong>SCHED_OTHER</strong> policy so long as its nice value falls within the range permitted by its <strong>RLIMIT_NICE</strong> resource limit (see <strong>getrlimit</strong>(2)).</p></li>
</ul>
<p>Privileged (<strong>CAP_SYS_NICE</strong>) threads ignore the <strong>RLIMIT_RTPRIO</strong> limit; as with older kernels, they can make arbitrary changes to scheduling policy and priority. See <strong>getrlimit</strong>(2) for further information on <strong>RLIMIT_RTPRIO</strong>.</p>
<h2>Limiting the CPU usage of real-time and deadline processes</h2>
<p>A nonblocking infinite loop in a thread scheduled under the <strong>SCHED_FIFO</strong>, <strong>SCHED_RR</strong>, or <strong>SCHED_DEADLINE</strong> policy can potentially block all other threads from accessing the CPU forever. Prior to Linux 2.6.25, the only way of preventing a runaway real-time process from freezing the system was to run (at the console) a shell scheduled under a higher static priority than the tested application. This allows an emergency kill of tested real-time applications that do not block or terminate as expected.</p>
<p>Since Linux 2.6.25, there are other techniques for dealing with runaway real-time and deadline processes. One of these is to use the <strong>RLIMIT_RTTIME</strong> resource limit to set a ceiling on the CPU time that a real-time process may consume. See <strong>getrlimit</strong>(2) for details.</p>
<p>Since version 2.6.25, Linux also provides two <em>/proc</em> files that can be used to reserve a certain amount of CPU time to be used by non-real-time processes. Reserving CPU time in this fashion allows some CPU time to be allocated to (say) a root shell that can be used to kill a runaway process. Both of these files specify time values in microseconds:</p>
<dl>
<dt><em>/proc/sys/kernel/sched_rt_period_us</em></dt>
<dd><p>This file specifies a scheduling period that is equivalent to 100% CPU bandwidth. The value in this file can range from 1 to <strong>INT_MAX</strong>, giving an operating range of 1 microsecond to around 35 minutes. The default value in this file is 1,000,000 (1 second).</p>
</dd>
<dt><em>/proc/sys/kernel/sched_rt_runtime_us</em></dt>
<dd><p>The value in this file specifies how much of the "period" time can be used by all real-time and deadline scheduled processes on the system. The value in this file can range from -1 to <strong>INT_MAX</strong>-1. Specifying -1 makes the run time the same as the period; that is, no CPU time is set aside for non-real-time processes (which was the Linux behavior before kernel 2.6.25). The default value in this file is 950,000 (0.95 seconds), meaning that 5% of the CPU time is reserved for processes that don't run under a real-time or deadline scheduling policy.</p>
</dd>
</dl>
<h2>Response time</h2>
<p>A blocked high priority thread waiting for I/O has a certain response time before it is scheduled again. The device driver writer can greatly reduce this response time by using a "slow interrupt" interrupt handler.</p>
<h2>Miscellaneous</h2>
<p>Child processes inherit the scheduling policy and parameters across a <strong>fork</strong>(2). The scheduling policy and parameters are preserved across <strong>execve</strong>(2).</p>
<p>Memory locking is usually needed for real-time processes to avoid paging delays; this can be done with <strong>mlock</strong>(2) or <strong>mlockall</strong>(2).</p>
<h2>The autogroup feature</h2>
<p>Since Linux 2.6.38, the kernel provides a feature known as autogrouping to improve interactive desktop performance in the face of multiprocess, CPU-intensive workloads such as building the Linux kernel with large numbers of parallel build processes (i.e., the <strong>make</strong>(1) <strong>-j</strong> flag).</p>
<p>This feature operates in conjunction with the CFS scheduler and requires a kernel that is configured with <strong>CONFIG_SCHED_AUTOGROUP</strong>. On a running system, this feature is enabled or disabled via the file <em>/proc/sys/kernel/sched_autogroup_enabled</em>; a value of 0 disables the feature, while a value of 1 enables it. The default value in this file is 1, unless the kernel was booted with the <em>noautogroup</em> parameter.</p>
<p>A new autogroup is created when a new session is created via <strong>setsid</strong>(2); this happens, for example, when a new terminal window is started. A new process created by <strong>fork</strong>(2) inherits its parent's autogroup membership. Thus, all of the processes in a session are members of the same autogroup. An autogroup is automatically destroyed when the last process in the group terminates.</p>
<p>When autogrouping is enabled, all of the members of an autogroup are placed in the same kernel scheduler "task group". The CFS scheduler employs an algorithm that equalizes the distribution of CPU cycles across task groups. The benefits of this for interactive desktop performance can be described via the following example.</p>
<p>Suppose that there are two autogroups competing for the same CPU (i.e., presume either a single CPU system or the use of <strong>taskset</strong>(1) to confine all the processes to the same CPU on an SMP system). The first group contains ten CPU-bound processes from a kernel build started with <em>make -j10</em>. The other contains a single CPU-bound process: a video player. The effect of autogrouping is that the two groups will each receive half of the CPU cycles. That is, the video player will receive 50% of the CPU cycles, rather than just 9% of the cycles, which would likely lead to degraded video playback. The situation on an SMP system is more complex, but the general effect is the same: the scheduler distributes CPU cycles across task groups such that an autogroup that contains a large number of CPU-bound processes does not end up hogging CPU cycles at the expense of the other jobs on the system.</p>
<p>A process's autogroup (task group) membership can be viewed via the file <em>/proc/[pid]/autogroup</em>:</p>
<pre><code>$ cat /proc/1/autogroup
/autogroup-1 nice 0</code></pre>
<p>This file can also be used to modify the CPU bandwidth allocated to an autogroup. This is done by writing a number in the "nice" range to the file to set the autogroup's nice value. The allowed range is from +19 (low priority) to -20 (high priority). (Writing values outside of this range causes <strong>write</strong>(2) to fail with the error <strong>EINVAL</strong>.)</p>
<p>The autogroup nice setting has the same meaning as the process nice value, but applies to distribution of CPU cycles to the autogroup as a whole, based on the relative nice values of other autogroups. For a process inside an autogroup, the CPU cycles that it receives will be a product of the autogroup's nice value (compared to other autogroups) and the process's nice value (compared to other processes in the same autogroup.</p>
<p>The use of the <strong>cgroups</strong>(7) CPU controller to place processes in cgroups other than the root CPU cgroup overrides the effect of autogrouping.</p>
<p>The autogroup feature groups only processes scheduled under non-real-time policies (<strong>SCHED_OTHER</strong>, <strong>SCHED_BATCH</strong>, and <strong>SCHED_IDLE</strong>). It does not group processes scheduled under real-time and deadline policies. Those processes are scheduled according to the rules described earlier.</p>
<h2>The nice value and group scheduling</h2>
<p>When scheduling non-real-time processes (i.e., those scheduled under the <strong>SCHED_OTHER</strong>, <strong>SCHED_BATCH</strong>, and <strong>SCHED_IDLE</strong> policies), the CFS scheduler employs a technique known as "group scheduling", if the kernel was configured with the <strong>CONFIG_FAIR_GROUP_SCHED</strong> option (which is typical).</p>
<p>Under group scheduling, threads are scheduled in "task groups". Task groups have a hierarchical relationship, rooted under the initial task group on the system, known as the "root task group". Task groups are formed in the following circumstances:</p>
<ul>
<li><p>All of the threads in a CPU cgroup form a task group. The parent of this task group is the task group of the corresponding parent cgroup.</p></li>
<li><p>If autogrouping is enabled, then all of the threads that are (implicitly) placed in an autogroup (i.e., the same session, as created by <strong>setsid</strong>(2)) form a task group. Each new autogroup is thus a separate task group. The root task group is the parent of all such autogroups.</p></li>
<li><p>If autogrouping is enabled, then the root task group consists of all processes in the root CPU cgroup that were not otherwise implicitly placed into a new autogroup.</p></li>
<li><p>If autogrouping is disabled, then the root task group consists of all processes in the root CPU cgroup.</p></li>
<li><p>If group scheduling was disabled (i.e., the kernel was configured without <strong>CONFIG_FAIR_GROUP_SCHED</strong>), then all of the processes on the system are notionally placed in a single task group.</p></li>
</ul>
<p>Under group scheduling, a thread's nice value has an effect for scheduling decisions <em>only relative to other threads in the same task group</em>. This has some surprising consequences in terms of the traditional semantics of the nice value on UNIX systems. In particular, if autogrouping is enabled (which is the default in various distributions), then employing <strong>setpriority</strong>(2) or <strong>nice</strong>(1) on a process has an effect only for scheduling relative to other processes executed in the same session (typically: the same terminal window).</p>
<p>Conversely, for two processes that are (for example) the sole CPU-bound processes in different sessions (e.g., different terminal windows, each of whose jobs are tied to different autogroups), <em>modifying the nice value of the process in one of the sessions</em> <em>has no effect</em> in terms of the scheduler's decisions relative to the process in the other session. A possibly useful workaround here is to use a command such as the following to modify the autogroup nice value for <em>all</em> of the processes in a terminal session:</p>
<pre><code>$ echo 10 &gt; /proc/self/autogroup</code></pre>
<h2>Real-time features in the mainline Linux kernel</h2>
<p>Since kernel version 2.6.18, Linux is gradually becoming equipped with real-time capabilities, most of which are derived from the former <em>realtime-preempt</em> patch set. Until the patches have been completely merged into the mainline kernel, they must be installed to achieve the best real-time performance. These patches are named:</p>
<pre><code>patch-kernelversion-rtpatchversion</code></pre>
<p>and can be downloaded from <a href="http://www.kernel.org/pub/linux/kernel/projects/rt/"></a>.</p>
<p>Without the patches and prior to their full inclusion into the mainline kernel, the kernel configuration offers only the three preemption classes <strong>CONFIG_PREEMPT_NONE</strong>, <strong>CONFIG_PREEMPT_VOLUNTARY</strong>, and <strong>CONFIG_PREEMPT_DESKTOP</strong> which respectively provide no, some, and considerable reduction of the worst-case scheduling latency.</p>
<p>With the patches applied or after their full inclusion into the mainline kernel, the additional configuration item <strong>CONFIG_PREEMPT_RT</strong> becomes available. If this is selected, Linux is transformed into a regular real-time operating system. The FIFO and RR scheduling policies are then used to run a thread with true real-time priority and a minimum worst-case scheduling latency.</p>
<h1>NOTES</h1>
<p>The <strong>cgroups</strong>(7) CPU controller can be used to limit the CPU consumption of groups of processes.</p>
<p>Originally, Standard Linux was intended as a general-purpose operating system being able to handle background processes, interactive applications, and less demanding real-time applications (applications that need to usually meet timing deadlines). Although the Linux kernel 2.6 allowed for kernel preemption and the newly introduced O(1) scheduler ensures that the time needed to schedule is fixed and deterministic irrespective of the number of active tasks, true real-time computing was not possible up to kernel version 2.6.17.</p>
<h1>SEE ALSO</h1>
<p><strong>chcpu</strong>(1), <strong>chrt</strong>(1), <strong>lscpu</strong>(1), <strong>ps</strong>(1), <strong>taskset</strong>(1), <strong>top</strong>(1), <strong>getpriority</strong>(2), <strong>mlock</strong>(2), <strong>mlockall</strong>(2), <strong>munlock</strong>(2), <strong>munlockall</strong>(2), <strong>nice</strong>(2), <strong>sched_get_priority_max</strong>(2), <strong>sched_get_priority_min</strong>(2), <strong>sched_getaffinity</strong>(2), <strong>sched_getparam</strong>(2), <strong>sched_getscheduler</strong>(2), <strong>sched_rr_get_interval</strong>(2), <strong>sched_setaffinity</strong>(2), <strong>sched_setparam</strong>(2), <strong>sched_setscheduler</strong>(2), <strong>sched_yield</strong>(2), <strong>setpriority</strong>(2), <strong>pthread_getaffinity_np</strong>(3), <strong>pthread_getschedparam</strong>(3), <strong>pthread_setaffinity_np</strong>(3), <strong>sched_getcpu</strong>(3), <strong>capabilities</strong>(7), <strong>cpuset</strong>(7)</p>
<p><em>Programming for the real world - POSIX.4</em> by Bill O. Gallmeister, O'Reilly &amp; Associates, Inc., ISBN 1-56592-074-0.</p>
<p>The Linux kernel source files <em>Documentation/scheduler/sched-deadline.txt</em>, <em>Documentation/scheduler/sched-rt-group.txt</em>, <em>Documentation/scheduler/sched-design-CFS.txt</em>, and <em>Documentation/scheduler/sched-nice-design.txt</em></p>
<h1>COLOPHON</h1>
<p>This page is part of release 5.10 of the Linux <em>man-pages</em> project. A description of the project, information about reporting bugs, and the latest version of this page, can be found at https://www.kernel.org/doc/man-pages/.</p>
<footer style="text-align: center;"><a href="https://blog.tamer.pw" target="_blank">Blog</a> | <a href="https://github.com/linuxtamer" target="_blank">Contact</a></footer>
</div>
</body>
</html>

